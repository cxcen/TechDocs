# Aptos Consensus æ¨¡å—æ·±åº¦æŠ€æœ¯æ–‡æ¡£(è¯¦ç»†å¢å¼ºç‰ˆ - Part 7)

## QuorumStore æ¨¡å—æ·±åº¦è§£æ

> **æ¨¡å—è·¯å¾„**: `src/quorum_store/`
> **æ ¸å¿ƒèŒè´£**: æ‰¹é‡äº¤æ˜“å¤„ç†ã€è§£è€¦å…±è¯†ä¸æ•°æ®ä¼ æ’­ã€åŠ¨æ€åå‹æ§åˆ¶
> **æ–‡æ¡£ç‰ˆæœ¬**: v2.0 (è¯¦ç»†å¢å¼ºç‰ˆ)
> **ç”Ÿæˆæ—¶é—´**: 2025-10-09

---

## ğŸ“‘ ç›®å½•

- [1. QuorumStore æ¦‚è¿°](#1-quorumstore-æ¦‚è¿°)
  - [1.1 è®¾è®¡ç†å¿µä¸åŠ¨æœº](#11-è®¾è®¡ç†å¿µä¸åŠ¨æœº)
  - [1.2 æ ¸å¿ƒæ¶æ„](#12-æ ¸å¿ƒæ¶æ„)
  - [1.3 æ–‡ä»¶ç»„ç»‡ç»“æ„](#13-æ–‡ä»¶ç»„ç»‡ç»“æ„)
- [2. æ ¸å¿ƒæ•°æ®ç»“æ„è¯¦è§£](#2-æ ¸å¿ƒæ•°æ®ç»“æ„è¯¦è§£)
  - [2.1 Batch ç»“æ„](#21-batch-ç»“æ„)
  - [2.2 ProofOfStore ç»“æ„](#22-proofofstore-ç»“æ„)
  - [2.3 BatchInfo ä¸ç­¾å](#23-batchinfo-ä¸ç­¾å)
- [3. BatchGenerator æ·±åº¦è§£æ](#3-batchgenerator-æ·±åº¦è§£æ)
  - [3.1 BatchGenerator ç»“æ„](#31-batchgenerator-ç»“æ„)
  - [3.2 æ‰¹æ¬¡ç”Ÿæˆæµç¨‹](#32-æ‰¹æ¬¡ç”Ÿæˆæµç¨‹)
  - [3.3 äº¤æ˜“å»é‡æœºåˆ¶](#33-äº¤æ˜“å»é‡æœºåˆ¶)
  - [3.4 è¿‡æœŸç®¡ç†](#34-è¿‡æœŸç®¡ç†)
- [4. BatchStore å­˜å‚¨å±‚è¯¦è§£](#4-batchstore-å­˜å‚¨å±‚è¯¦è§£)
  - [4.1 ä¸‰çº§å­˜å‚¨æ¶æ„](#41-ä¸‰çº§å­˜å‚¨æ¶æ„)
  - [4.2 é…é¢ç®¡ç†æœºåˆ¶](#42-é…é¢ç®¡ç†æœºåˆ¶)
  - [4.3 æ‰¹æ¬¡æŒä¹…åŒ–](#43-æ‰¹æ¬¡æŒä¹…åŒ–)
  - [4.4 ç­¾åä¸éªŒè¯](#44-ç­¾åä¸éªŒè¯)
- [5. ProofCoordinator è¯æ˜åè°ƒå™¨](#5-proofcoordinator-è¯æ˜åè°ƒå™¨)
  - [5.1 ç­¾åæ”¶é›†æœºåˆ¶](#51-ç­¾åæ”¶é›†æœºåˆ¶)
  - [5.2 èšåˆç­¾åç®—æ³•](#52-èšåˆç­¾åç®—æ³•)
  - [5.3 ProofOfStore ç”Ÿæˆ](#53-proofofstore-ç”Ÿæˆ)
- [6. ProofManager è¯æ˜ç®¡ç†å™¨](#6-proofmanager-è¯æ˜ç®¡ç†å™¨)
  - [6.1 Proof ç¼“å­˜ç®¡ç†](#61-proof-ç¼“å­˜ç®¡ç†)
  - [6.2 æ‹‰å–ç­–ç•¥](#62-æ‹‰å–ç­–ç•¥)
  - [6.3 æ¸…ç†æœºåˆ¶](#63-æ¸…ç†æœºåˆ¶)
- [7. åå‹æœºåˆ¶è¯¦è§£](#7-åå‹æœºåˆ¶è¯¦è§£)
  - [7.1 åå‹è§¦å‘æ¡ä»¶](#71-åå‹è§¦å‘æ¡ä»¶)
  - [7.2 åŠ¨æ€è°ƒæ§ç®—æ³•](#72-åŠ¨æ€è°ƒæ§ç®—æ³•)
  - [7.3 å¤šçº§åå‹ç­–ç•¥](#73-å¤šçº§åå‹ç­–ç•¥)
- [8. ç½‘ç»œå±‚äº¤äº’](#8-ç½‘ç»œå±‚äº¤äº’)
  - [8.1 æ¶ˆæ¯ç±»å‹](#81-æ¶ˆæ¯ç±»å‹)
  - [8.2 å¹¿æ’­æœºåˆ¶](#82-å¹¿æ’­æœºåˆ¶)
  - [8.3 è¯·æ±‚ä¸å“åº”](#83-è¯·æ±‚ä¸å“åº”)
- [9. Batch å®Œæ•´ç”Ÿå‘½å‘¨æœŸ](#9-batch-å®Œæ•´ç”Ÿå‘½å‘¨æœŸ)
- [10. æ€§èƒ½ä¼˜åŒ–ä¸é…ç½®](#10-æ€§èƒ½ä¼˜åŒ–ä¸é…ç½®)
- [11. æ€»ç»“](#11-æ€»ç»“)

---

## 1. QuorumStore æ¦‚è¿°

### 1.1 è®¾è®¡ç†å¿µä¸åŠ¨æœº

#### ä¼ ç»Ÿå…±è¯†çš„æ•°æ®ä¼ æ’­ç“¶é¢ˆ

```mermaid
mindmap
  root((ä¼ ç»Ÿå…±è¯†ç“¶é¢ˆ))
    æ•°æ®ä¼ æ’­
      æ¯ä¸ªåŒºå—éƒ½å¹¿æ’­å®Œæ•´äº¤æ˜“
      ç½‘ç»œå¸¦å®½æµªè´¹
      é‡å¤æ•°æ®ä¼ è¾“
    å…±è¯†è€¦åˆ
      æ•°æ®ä¼ æ’­ä¸å…±è¯†ç»‘å®š
      Leader å‹åŠ›å¤§
      æ‰©å±•æ€§å·®
    å³°å€¼å¤„ç†
      çªå‘æµé‡æ— ç¼“å†²
      ç³»ç»Ÿä¸ç¨³å®š
      å»¶è¿Ÿé£™å‡
    èµ„æºåˆ©ç”¨
      å¸¦å®½åˆ©ç”¨ç‡ä½
      å­˜å‚¨å†—ä½™é«˜
      CPU ç©ºé—²æœŸå¤š
```

**é—®é¢˜è¯¦è§£**ï¼š

```mermaid
graph TD
    subgraph "ä¼ ç»Ÿæ¨¡å¼ - æ¯ä¸ªåŒºå—éƒ½ä¼ è¾“å®Œæ•´æ•°æ®"
        L1[Leader Round 1]
        L2[Leader Round 2]
        L3[Leader Round 3]

        L1 -->|1000 txns<br/>500KB| V1[Validators]
        L2 -->|1000 txns<br/>500KB| V2[Validators]
        L3 -->|1000 txns<br/>500KB| V3[Validators]
    end

    Note1[é—®é¢˜:<br/>1. æ¯è½®éƒ½ä¼ è¾“å®Œæ•´äº¤æ˜“<br/>2. å¸¦å®½æ¶ˆè€—: 500KB Ã— 3 = 1.5MB<br/>3. ç½‘ç»œæ‹¥å¡,å»¶è¿Ÿé«˜]

    style L1 fill:#ffcdd2
    style L2 fill:#ffcdd2
    style L3 fill:#ffcdd2
```

#### QuorumStore è§£å†³æ–¹æ¡ˆ

```mermaid
graph TB
    subgraph "QuorumStore æ¨¡å¼ - è§£è€¦æ•°æ®ä¸å…±è¯†"
        subgraph "é˜¶æ®µ 1: æ•°æ®ä¼ æ’­ (å¼‚æ­¥)"
            BG1[Validator A<br/>ç”Ÿæˆ Batch1]
            BG2[Validator B<br/>ç”Ÿæˆ Batch2]
            BG3[Validator C<br/>ç”Ÿæˆ Batch3]

            BG1 -->|å¹¿æ’­äº¤æ˜“| NET1[Network]
            BG2 -->|å¹¿æ’­äº¤æ˜“| NET1
            BG3 -->|å¹¿æ’­äº¤æ˜“| NET1

            NET1 -->|æŒä¹…åŒ–| STORE[All Validators<br/>æœ¬åœ°å­˜å‚¨]
        end

        subgraph "é˜¶æ®µ 2: è¯æ˜ç”Ÿæˆ"
            STORE -->|ç­¾å| SIG[2f+1 ç­¾å]
            SIG -->|èšåˆ| PROOF[ProofOfStore]
        end

        subgraph "é˜¶æ®µ 3: å…±è¯† (è½»é‡)"
            L1[Leader Round 1]
            L2[Leader Round 2]

            L1 -->|ä»…å¹¿æ’­ Proof<br/>~1KB| V1[Validators]
            L2 -->|ä»…å¹¿æ’­ Proof<br/>~1KB| V2[Validators]
        end

        PROOF --> L1
        PROOF --> L2
    end

    Note2[ä¼˜åŠ¿:<br/>1. æ•°æ®åªä¼ è¾“ä¸€æ¬¡<br/>2. å…±è¯†åªä¼  Proof<br/>3. å¸¦å®½èŠ‚çœ 50-70%]

    style BG1 fill:#c8e6c9
    style BG2 fill:#c8e6c9
    style BG3 fill:#c8e6c9
    style PROOF fill:#fff9c4
    style L1 fill:#e1f5ff
    style L2 fill:#e1f5ff
```

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š

| ç»´åº¦ | ä¼ ç»Ÿæ¨¡å¼ | QuorumStore æ¨¡å¼ | æ”¹è¿›å¹…åº¦ |
|-----|---------|-----------------|---------|
| **ç½‘ç»œå¸¦å®½** | æ¯è½®ä¼ è¾“å®Œæ•´äº¤æ˜“ | äº¤æ˜“ä¼ è¾“ä¸€æ¬¡ + Proof | **50-70% â†“** |
| **å…±è¯†å»¶è¿Ÿ** | æ•°æ®ä¼ æ’­é˜»å¡å…±è¯† | è§£è€¦å¹¶è¡Œ | **30% â†“** |
| **ååé‡** | Leader ç“¶é¢ˆ | å¤šèŠ‚ç‚¹å¹¶è¡Œæ‰¹å¤„ç† | **3-5å€** |
| **å³°å€¼å¤„ç†** | æ— ç¼“å†²æœºåˆ¶ | åŠ¨æ€åå‹ | **å¹³æ»‘è´Ÿè½½** |
| **å­˜å‚¨å¤ç”¨** | æ—  | Batch å¯è¢«å¤šä¸ªåŒºå—å¼•ç”¨ | **é«˜å¤ç”¨ç‡** |

### 1.2 æ ¸å¿ƒæ¶æ„

#### å®Œæ•´æ¶æ„å›¾

```mermaid
graph TB
    subgraph "å¤–éƒ¨æ¥å£å±‚"
        MP[Mempool<br/>â”â”â”â”â”â”â”â”â”â”<br/>äº¤æ˜“æ± ]
        PG[ProposalGenerator<br/>â”â”â”â”â”â”â”â”â”â”<br/>åŒºå—ç”Ÿæˆå™¨]
        EX[Executor<br/>â”â”â”â”â”â”â”â”â”â”<br/>æ‰§è¡Œå™¨]
    end

    subgraph "QuorumStore æ ¸å¿ƒå±‚"
        BG[BatchGenerator<br/>â”â”â”â”â”â”â”â”â”â”<br/>æ‰¹æ¬¡ç”Ÿæˆå™¨]
        BS[BatchStore<br/>â”â”â”â”â”â”â”â”â”â”<br/>æ‰¹æ¬¡å­˜å‚¨]
        PC[ProofCoordinator<br/>â”â”â”â”â”â”â”â”â”â”<br/>è¯æ˜åè°ƒå™¨]
        PM[ProofManager<br/>â”â”â”â”â”â”â”â”â”â”<br/>è¯æ˜ç®¡ç†å™¨]
        BC[BatchCoordinator<br/>â”â”â”â”â”â”â”â”â”â”<br/>æ‰¹æ¬¡åè°ƒå™¨]
        BR[BatchRequester<br/>â”â”â”â”â”â”â”â”â”â”<br/>æ‰¹æ¬¡è¯·æ±‚å™¨]
        BP[BackPressure<br/>â”â”â”â”â”â”â”â”â”â”<br/>åå‹æ§åˆ¶å™¨]
    end

    subgraph "å­˜å‚¨å±‚"
        QDB[(QuorumStoreDB<br/>â”â”â”â”â”â”â”â”â”â”<br/>RocksDB æŒä¹…åŒ–)]
        Cache[DashMap<br/>â”â”â”â”â”â”â”â”â”â”<br/>å†…å­˜ç¼“å­˜]
        QM[QuotaManager<br/>â”â”â”â”â”â”â”â”â”â”<br/>é…é¢ç®¡ç†]
    end

    subgraph "ç½‘ç»œå±‚"
        NET[NetworkSender<br/>â”â”â”â”â”â”â”â”â”â”<br/>ç½‘ç»œå‘é€å™¨]
        RPC[RpcHandler<br/>â”â”â”â”â”â”â”â”â”â”<br/>RPC å¤„ç†å™¨]
    end

    MP -->|pull_txns| BG
    BG -->|persist_batch| BS
    BS -->|store| QDB
    BS -->|cache| Cache
    QM -->|quota_check| BS

    BG -->|broadcast_batch| NET
    NET -->|BatchMsg| BC
    BC -->|store_remote| BS

    BS -->|sign_batch_info| PC
    PC -->|collect_signatures| PC
    PC -->|aggregate| PM

    PM -->|pull_proofs| PG
    PG -->|request_missing_batches| BR
    BR -->|rpc_request| RPC
    RPC -->|fetch_batch| NET

    BP -->|monitor| BG
    BP -->|throttle| PM

    PM -->|provide_proofs| PG
    PG -->|execute_block| EX
    EX -->|commit_notify| BG

    style BG fill:#4caf50,stroke:#333,stroke-width:3px
    style BS fill:#2196f3,stroke:#333,stroke-width:3px
    style PC fill:#ff9800,stroke:#333,stroke-width:3px
    style PM fill:#e91e63,stroke:#333,stroke-width:3px
    style BP fill:#f44336,stroke:#333,stroke-width:3px
```

#### æ•°æ®æµè¯¦å›¾

```mermaid
sequenceDiagram
    autonumber
    participant MP as Mempool
    participant BG as BatchGenerator
    participant BS as BatchStore
    participant NET as Network
    participant PC as ProofCoordinator
    participant PM as ProofManager
    participant PG as ProposalGenerator
    participant EX as Executor

    Note over MP,EX: â•â•â•â•â•â•â•â•â•â• å®Œæ•´æ•°æ®æµ â•â•â•â•â•â•â•â•â•â•

    rect rgb(225, 245, 255)
        Note over BG: Phase 1: æ‰¹æ¬¡ç”Ÿæˆ
        BG->>BG: timer tick (100ms)
        BG->>MP: pull_txns(max_txns, excluded)
        MP->>BG: Vec<SignedTransaction>
        BG->>BG: create Batch
        BG->>BS: persist_batch(batch)
        BS->>BS: quota_check
        BS->>BS: write to DB + cache
        BS->>BG: SignedBatchInfo
    end

    rect rgb(255, 249, 196)
        Note over NET: Phase 2: ç½‘ç»œå¹¿æ’­
        BG->>NET: broadcast BatchMsg
        NET->>NET: send to all validators
    end

    rect rgb(243, 229, 245)
        Note over PC: Phase 3: ç­¾åæ”¶é›†
        NET->>PC: receive BatchMsg (remote)
        PC->>BS: persist remote batch
        PC->>PC: sign BatchInfo
        PC->>NET: send SignedBatchInfoMsg
        NET->>PC: collect signatures
        PC->>PC: voting_power >= 2f+1?
        PC->>PC: aggregate signatures
        PC->>PM: ProofOfStore ready
    end

    rect rgb(200, 230, 201)
        Note over PG: Phase 4: åŒºå—ææ¡ˆ
        PG->>PM: pull_proofs(max_bytes)
        PM->>PG: Vec<ProofOfStore>
        PG->>PG: construct block
        PG->>NET: broadcast proposal
    end

    rect rgb(255, 235, 238)
        Note over EX: Phase 5: æ‰§è¡Œä¸æ¸…ç†
        EX->>EX: execute block
        EX->>BG: commit_notify(committed_batches)
        BG->>BS: cleanup expired batches
        BS->>BS: release quota
    end
```

### 1.3 æ–‡ä»¶ç»„ç»‡ç»“æ„

#### è¯¦ç»†ç›®å½•æ ‘

```
src/quorum_store/
â”œâ”€â”€ mod.rs                              # æ¨¡å—å…¥å£ (150 LOC)
â”‚   â””â”€â”€ QuorumStore æ¥å£å®šä¹‰
â”‚
â”œâ”€â”€ batch_generator.rs                  # æ‰¹æ¬¡ç”Ÿæˆå™¨ (1,800 LOC)
â”‚   â”œâ”€â”€ BatchGenerator ç»“æ„
â”‚   â”œâ”€â”€ generate_batch æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ insert_batch è¿œç¨‹æ‰¹æ¬¡å¤„ç†
â”‚   â”œâ”€â”€ handle_commit_notification
â”‚   â””â”€â”€ expiration management
â”‚
â”œâ”€â”€ batch_store.rs                      # æ‰¹æ¬¡å­˜å‚¨ (2,200 LOC)
â”‚   â”œâ”€â”€ BatchStore ç»“æ„
â”‚   â”œâ”€â”€ persist_batch æŒä¹…åŒ–
â”‚   â”œâ”€â”€ save_to_db RocksDB æ“ä½œ
â”‚   â”œâ”€â”€ get_batch ç¼“å­˜ + DB æŸ¥è¯¢
â”‚   â””â”€â”€ QuotaManager é…é¢ç®¡ç†
â”‚
â”œâ”€â”€ proof_coordinator.rs                # è¯æ˜åè°ƒå™¨ (1,500 LOC)
â”‚   â”œâ”€â”€ ProofCoordinator ç»“æ„
â”‚   â”œâ”€â”€ handle_batch_msg
â”‚   â”œâ”€â”€ handle_signed_batch_info_msg
â”‚   â”œâ”€â”€ aggregate_signatures
â”‚   â””â”€â”€ ProofAggregator çŠ¶æ€æœº
â”‚
â”œâ”€â”€ proof_manager.rs                    # è¯æ˜ç®¡ç†å™¨ (1,200 LOC)
â”‚   â”œâ”€â”€ ProofManager ç»“æ„
â”‚   â”œâ”€â”€ pull_proofs æ‹‰å–ç­–ç•¥
â”‚   â”œâ”€â”€ handle_commit_notification
â”‚   â””â”€â”€ ProofQueue ä¼˜å…ˆé˜Ÿåˆ—
â”‚
â”œâ”€â”€ batch_coordinator.rs                # æ‰¹æ¬¡åè°ƒå™¨ (800 LOC)
â”‚   â”œâ”€â”€ BatchCoordinator ç»“æ„
â”‚   â”œâ”€â”€ handle_batch_msg
â”‚   â””â”€â”€ éªŒè¯ä¸è½¬å‘é€»è¾‘
â”‚
â”œâ”€â”€ batch_requester.rs                  # æ‰¹æ¬¡è¯·æ±‚å™¨ (700 LOC)
â”‚   â”œâ”€â”€ BatchRequester ç»“æ„
â”‚   â”œâ”€â”€ request_batches RPC è¯·æ±‚
â”‚   â””â”€â”€ è¶…æ—¶ä¸é‡è¯•é€»è¾‘
â”‚
â”œâ”€â”€ counters.rs                         # Prometheus æŒ‡æ ‡ (400 LOC)
â”‚   â”œâ”€â”€ BATCH_GENERATOR_*
â”‚   â”œâ”€â”€ PROOF_COORDINATOR_*
â”‚   â””â”€â”€ QUOTA_MANAGER_*
â”‚
â”œâ”€â”€ quorum_store_coordinator.rs        # é¡¶å±‚åè°ƒå™¨ (600 LOC)
â”‚   â””â”€â”€ QuorumStoreCoordinator ç»“æ„
â”‚
â”œâ”€â”€ network_interface.rs                # ç½‘ç»œæ¥å£ (500 LOC)
â”‚   â”œâ”€â”€ QuorumStoreNetworkSender
â”‚   â””â”€â”€ QuorumStoreNetworkEvents
â”‚
â”œâ”€â”€ types.rs                            # ç±»å‹å®šä¹‰ (800 LOC)
â”‚   â”œâ”€â”€ Batch ç»“æ„
â”‚   â”œâ”€â”€ BatchInfo ç»“æ„
â”‚   â”œâ”€â”€ ProofOfStore ç»“æ„
â”‚   â”œâ”€â”€ SignedBatchInfo
â”‚   â””â”€â”€ å„ç§æ¶ˆæ¯ç±»å‹
â”‚
â”œâ”€â”€ utils/                              # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ time_expiration.rs             # è¿‡æœŸæ—¶é—´ç®¡ç† (200 LOC)
â”‚   â”œâ”€â”€ optimal_min_len.rs             # å¹¶è¡Œè®¡ç®—ä¼˜åŒ– (100 LOC)
â”‚   â””â”€â”€ payload_builder.rs             # Payload æ„å»º (300 LOC)
â”‚
â””â”€â”€ tests/                              # æµ‹è¯•
    â”œâ”€â”€ batch_generator_test.rs
    â”œâ”€â”€ proof_coordinator_test.rs
    â””â”€â”€ integration_test.rs
```

**ä»£ç è§„æ¨¡ç»Ÿè®¡**ï¼š

```mermaid
pie title QuorumStore æ¨¡å—ä»£ç è¡Œæ•°åˆ†å¸ƒ
    "batch_store.rs" : 2200
    "batch_generator.rs" : 1800
    "proof_coordinator.rs" : 1500
    "proof_manager.rs" : 1200
    "batch_coordinator.rs" : 800
    "types.rs" : 800
    "batch_requester.rs" : 700
    "quorum_store_coordinator.rs" : 600
    "network_interface.rs" : 500
    "counters.rs" : 400
    "utils" : 600
    "å…¶ä»–" : 900
```

---

## 2. æ ¸å¿ƒæ•°æ®ç»“æ„è¯¦è§£

### 2.1 Batch ç»“æ„

#### å®Œæ•´ç»“æ„å®šä¹‰

```mermaid
classDiagram
    class Batch {
        +BatchId batch_id
        +u64 epoch
        +Author author
        +u64 expiration_usecs
        +Vec~SignedTransaction~ transactions
        +u64 gas_bucket_start
        +num_txns() usize
        +num_bytes() usize
        +digest() HashValue
    }

    class BatchId {
        +u64 id
        +PeerId author
        +Ord trait
    }

    class SignedTransaction {
        +AccountAddress sender
        +u64 sequence_number
        +TransactionPayload payload
        +u64 gas_unit_price
        +u64 max_gas_amount
    }

    Batch --> BatchId
    Batch --> SignedTransaction
```

**ä»£ç å®ç°**ï¼š

```rust
// src/quorum_store/types.rs

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct Batch {
    /// æ‰¹æ¬¡å”¯ä¸€æ ‡è¯†
    batch_id: BatchId,

    /// Epoch ç¼–å·
    epoch: u64,

    /// æ‰¹æ¬¡ä½œè€…ï¼ˆç”Ÿæˆè¯¥æ‰¹æ¬¡çš„éªŒè¯è€…ï¼‰
    author: Author,

    /// è¿‡æœŸæ—¶é—´ï¼ˆå¾®ç§’ï¼‰
    expiration_usecs: u64,

    /// äº¤æ˜“åˆ—è¡¨
    transactions: Vec<SignedTransaction>,

    /// Gas bucket èµ·å§‹ä½ç½®ï¼ˆç”¨äºå…¬å¹³æ€§ï¼‰
    gas_bucket_start: u64,
}

impl Batch {
    /// åˆ›å»ºæ–°æ‰¹æ¬¡
    pub fn new(
        batch_id: BatchId,
        transactions: Vec<SignedTransaction>,
        epoch: u64,
        expiration_usecs: u64,
        author: Author,
        gas_bucket_start: u64,
    ) -> Self {
        Self {
            batch_id,
            epoch,
            author,
            expiration_usecs,
            transactions,
            gas_bucket_start,
        }
    }

    /// è®¡ç®—æ‰¹æ¬¡å“ˆå¸Œ
    pub fn digest(&self) -> HashValue {
        let batch_info = BatchInfo::new(
            self.author,
            self.batch_id,
            self.epoch,
            self.expiration_usecs,
            self.compute_transaction_hashes(),
            self.gas_bucket_start,
        );
        batch_info.digest()
    }

    /// è®¡ç®—äº¤æ˜“å“ˆå¸Œåˆ—è¡¨
    fn compute_transaction_hashes(&self) -> Vec<HashValue> {
        self.transactions
            .par_iter()
            .with_min_len(optimal_min_len(self.transactions.len(), 32))
            .map(|txn| txn.committed_hash())
            .collect()
    }

    /// äº¤æ˜“æ•°é‡
    pub fn num_txns(&self) -> usize {
        self.transactions.len()
    }

    /// æ‰¹æ¬¡å­—èŠ‚æ•°
    pub fn num_bytes(&self) -> usize {
        bcs::serialized_size(self).unwrap_or(0)
    }
}

/// æ‰¹æ¬¡ ID
#[derive(Clone, Copy, Debug, Eq, Hash, PartialEq, Serialize, Deserialize)]
pub struct BatchId {
    /// æ‰¹æ¬¡åºå·
    pub id: u64,

    /// ä½œè€…ï¼ˆç”¨äºå”¯ä¸€æ€§ï¼‰
    pub author: PeerId,
}

impl Ord for BatchId {
    fn cmp(&self, other: &Self) -> Ordering {
        // å…ˆæŒ‰ id æ’åºï¼Œå†æŒ‰ author æ’åº
        self.id.cmp(&other.id)
            .then_with(|| self.author.cmp(&other.author))
    }
}
```

### 2.2 ProofOfStore ç»“æ„

#### å®Œæ•´å®šä¹‰

```mermaid
classDiagram
    class ProofOfStore {
        +BatchInfo batch_info
        +AggregateSignature multi_signature
        +verify(verifier) Result
        +batch_id() BatchId
        +gas_bucket_start() u64
        +num_txns() usize
        +expiration() u64
    }

    class BatchInfo {
        +Author author
        +BatchId batch_id
        +u64 epoch
        +u64 expiration_usecs
        +Vec~HashValue~ txn_hashes
        +u64 gas_bucket_start
        +digest() HashValue
    }

    class AggregateSignature {
        +Vec~AccountAddress~ signers
        +Signature signature
        +verify_multi_sig() Result
    }

    ProofOfStore --> BatchInfo
    ProofOfStore --> AggregateSignature
```

**ä»£ç å®ç°**ï¼š

```rust
/// ProofOfStore - æ‰¹æ¬¡çš„ 2f+1 èšåˆç­¾åè¯æ˜
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct ProofOfStore {
    /// æ‰¹æ¬¡ä¿¡æ¯
    info: BatchInfo,

    /// èšåˆç­¾åï¼ˆæ¥è‡ª 2f+1 éªŒè¯è€…ï¼‰
    multi_signature: AggregateSignature,
}

impl ProofOfStore {
    pub fn new(info: BatchInfo, multi_signature: AggregateSignature) -> Self {
        Self {
            info,
            multi_signature,
        }
    }

    /// éªŒè¯ ProofOfStore
    pub fn verify(&self, verifier: &ValidatorVerifier) -> anyhow::Result<()> {
        // 1. éªŒè¯ç­¾åæ•°é‡
        ensure!(
            self.multi_signature.num_signatures() >= verifier.quorum_size(),
            "Insufficient signatures: {} < {}",
            self.multi_signature.num_signatures(),
            verifier.quorum_size()
        );

        // 2. éªŒè¯èšåˆç­¾å
        let message = self.info.digest();
        verifier.verify_multi_signature(&message, &self.multi_signature)?;

        Ok(())
    }

    pub fn batch_id(&self) -> BatchId {
        self.info.batch_id()
    }

    pub fn expiration(&self) -> u64 {
        self.info.expiration_usecs()
    }

    pub fn num_txns(&self) -> usize {
        self.info.num_txns()
    }

    pub fn num_bytes(&self) -> usize {
        // ProofOfStore åªåŒ…å«å…ƒæ•°æ®ï¼Œä¸åŒ…å«äº¤æ˜“å†…å®¹
        // å¤§çº¦ 1-2KB
        bcs::serialized_size(self).unwrap_or(0)
    }
}

/// BatchInfo - æ‰¹æ¬¡å…ƒæ•°æ®
#[derive(Clone, Debug, Eq, Hash, PartialEq, Serialize, Deserialize)]
pub struct BatchInfo {
    author: Author,
    batch_id: BatchId,
    epoch: u64,
    expiration_usecs: u64,

    /// äº¤æ˜“å“ˆå¸Œåˆ—è¡¨ï¼ˆä¸æ˜¯å®Œæ•´äº¤æ˜“ï¼‰
    txn_hashes: Vec<HashValue>,

    gas_bucket_start: u64,
}

impl BatchInfo {
    /// è®¡ç®— BatchInfo çš„å“ˆå¸Œï¼ˆç”¨äºç­¾åï¼‰
    pub fn digest(&self) -> HashValue {
        let mut state = DefaultHasher::new();
        bcs::serialize_into(&mut state, self).unwrap();
        HashValue::sha3_256_of(state.finish().to_le_bytes().as_ref())
    }

    pub fn num_txns(&self) -> usize {
        self.txn_hashes.len()
    }
}
```

### 2.3 BatchInfo ä¸ç­¾å

#### ç­¾åæµç¨‹å¯è§†åŒ–

```mermaid
graph TD
    A[Batch åˆ›å»º] --> B[è®¡ç®— BatchInfo]
    B --> C[BatchInfo.digest]

    C --> D[Validator A ç­¾å]
    C --> E[Validator B ç­¾å]
    C --> F[Validator C ç­¾å]
    C --> G[Validator D ç­¾å]

    D --> H[æ”¶é›†ç­¾å]
    E --> H
    F --> H
    G --> H

    H --> I{æŠ•ç¥¨æƒ >= 2f+1?}
    I -->|å¦| H
    I -->|æ˜¯| J[èšåˆç­¾å]

    J --> K[ç”Ÿæˆ ProofOfStore]
    K --> L[éªŒè¯ ProofOfStore]

    L --> M{éªŒè¯é€šè¿‡?}
    M -->|æ˜¯| N[å¯ç”¨äºåŒºå—ææ¡ˆ]
    M -->|å¦| O[ä¸¢å¼ƒ]

    style C fill:#fff9c4
    style J fill:#c8e6c9
    style K fill:#e1f5ff
```

**SignedBatchInfo ç»“æ„**ï¼š

```rust
/// å•ä¸ªéªŒè¯è€…å¯¹ BatchInfo çš„ç­¾å
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SignedBatchInfo {
    /// æ‰¹æ¬¡ä¿¡æ¯
    info: BatchInfo,

    /// ç­¾åè€…
    signer: Author,

    /// ç­¾å
    signature: bls12381::Signature,
}

impl SignedBatchInfo {
    pub fn new(info: BatchInfo, signer: Author, signature: bls12381::Signature) -> Self {
        Self {
            info,
            signer,
            signature,
        }
    }

    /// éªŒè¯ç­¾å
    pub fn verify(&self, verifier: &ValidatorVerifier) -> anyhow::Result<()> {
        let message = self.info.digest();
        verifier.verify_signature(self.signer, &message, &self.signature)
    }
}
```

---

## 3. BatchGenerator æ·±åº¦è§£æ

### 3.1 BatchGenerator ç»“æ„

#### å®Œæ•´æ•°æ®ç»“æ„

```rust
// src/quorum_store/batch_generator.rs

pub struct BatchGenerator {
    // ========================================
    // åŸºæœ¬ä¿¡æ¯
    // ========================================
    epoch: u64,
    my_peer_id: PeerId,

    /// æ‰¹æ¬¡ ID ç”Ÿæˆå™¨ï¼ˆè‡ªå¢ï¼‰
    batch_id: BatchId,

    // ========================================
    // å­˜å‚¨ä¸ç½‘ç»œ
    // ========================================
    db: Arc<dyn QuorumStoreStorage>,
    batch_writer: Arc<dyn BatchWriter>,
    network_sender: QuorumStoreNetworkSender,

    // ========================================
    // äº¤æ˜“è·Ÿè¸ª
    // ========================================
    /// æ­£åœ¨å¤„ç†çš„æ‰¹æ¬¡
    /// (PeerId, BatchId) -> BatchInProgress
    batches_in_progress: HashMap<(PeerId, BatchId), BatchInProgress>,

    /// æ­£åœ¨å¤„ç†çš„äº¤æ˜“ï¼ˆæŒ‰ gas æ’åºï¼‰
    /// TransactionSummary -> TransactionInProgress
    txns_in_progress_sorted: BTreeMap<TransactionSummary, TransactionInProgress>,

    // ========================================
    // è¿‡æœŸç®¡ç†
    // ========================================
    batch_expirations: TimeExpirations<(PeerId, BatchId)>,

    // ========================================
    // åå‹æ§åˆ¶
    // ========================================
    back_pressure: BackPressure,

    // ========================================
    // é…ç½®
    // ========================================
    config: QuorumStoreConfig,

    /// æœ€æ–°åŒºå—æ—¶é—´æˆ³ï¼ˆç”¨äºè®¡ç®—è¿‡æœŸæ—¶é—´ï¼‰
    latest_block_timestamp: u64,
}

/// æ­£åœ¨å¤„ç†çš„æ‰¹æ¬¡ä¿¡æ¯
struct BatchInProgress {
    batch_id: BatchId,
    num_txns: usize,
    num_bytes: usize,
    creation_time: Instant,
}

/// äº¤æ˜“æ‘˜è¦ï¼ˆç”¨äºå»é‡ï¼‰
#[derive(Clone, Eq, Hash, Ord, PartialEq, PartialOrd)]
struct TransactionSummary {
    sender: AccountAddress,
    sequence_number: u64,
    hash: HashValue,
}

/// æ­£åœ¨å¤„ç†çš„äº¤æ˜“ä¿¡æ¯
struct TransactionInProgress {
    gas_unit_price: u64,
    insertion_time: Instant,
}
```

#### BatchGenerator èŒè´£åˆ†è§£

```mermaid
mindmap
  root((BatchGenerator))
    æ‰¹æ¬¡ç”Ÿæˆ
      å®šæ—¶è§¦å‘ tick
      ä» Mempool æ‹‰å–
      è¿‡æ»¤é‡å¤äº¤æ˜“
      åˆ›å»º Batch å¯¹è±¡
    æŒä¹…åŒ–
      å†™å…¥ RocksDB
      å†…å­˜ç¼“å­˜
      é…é¢æ£€æŸ¥
    å¹¿æ’­
      å‘é€ BatchMsg
      ç½‘ç»œä¼ è¾“
    è¿‡æœŸç®¡ç†
      TimeExpirations
      å®šæœŸæ¸…ç†
      é‡Šæ”¾èµ„æº
    åå‹å¤„ç†
      æ£€æŸ¥åå‹çŠ¶æ€
      åŠ¨æ€è°ƒèŠ‚
      è·³è¿‡ç”Ÿæˆ
    æäº¤é€šçŸ¥
      æ¥æ”¶ commit äº‹ä»¶
      æ¸…ç†å·²æäº¤æ‰¹æ¬¡
      æ›´æ–°ç»Ÿè®¡
```

### 3.2 æ‰¹æ¬¡ç”Ÿæˆæµç¨‹

#### å®Œæ•´æµç¨‹å›¾

```mermaid
sequenceDiagram
    autonumber
    participant TM as Timer (100ms)
    participant BG as BatchGenerator
    participant BP as BackPressure
    participant MP as Mempool
    participant BS as BatchStore
    participant NET as Network
    participant PEERS as Other Validators

    Note over TM,PEERS: â•â•â•â•â•â•â•â•â•â• æ‰¹æ¬¡ç”Ÿæˆå®Œæ•´æµç¨‹ â•â•â•â•â•â•â•â•â•â•

    TM->>BG: tick event

    rect rgb(225, 245, 255)
        Note over BG,BP: Phase 1: æ£€æŸ¥åå‹
        BG->>BP: check_backpressure()
        BP->>BG: BackPressure { txn_count, proof_count }

        alt æœ‰åå‹
            BG->>BG: skip batch generation
            BG->>TM: return
        end
    end

    rect rgb(255, 249, 196)
        Note over BG,MP: Phase 2: æ‹‰å–äº¤æ˜“
        BG->>BG: calculate max_txns, max_bytes
        BG->>BG: build excluded_txns set
        BG->>MP: pull_internal(max, excluded)
        MP->>BG: Vec<SignedTransaction>

        alt äº¤æ˜“ä¸ºç©º
            BG->>TM: return
        end
    end

    rect rgb(243, 229, 245)
        Note over BG: Phase 3: åˆ›å»ºæ‰¹æ¬¡
        BG->>BG: batch_id = next_batch_id()
        BG->>BG: expiration = now + config.expiry_time
        BG->>BG: batch = Batch::new(...)
        BG->>BG: update txns_in_progress_sorted
        BG->>BG: update batches_in_progress
    end

    rect rgb(200, 230, 201)
        Note over BS: Phase 4: æŒä¹…åŒ–
        BG->>BS: persist_batch(batch)
        BS->>BS: quota_check()
        BS->>BS: write to RocksDB
        BS->>BS: add to cache
        BS->>BS: sign BatchInfo
        BS->>BG: SignedBatchInfo
    end

    rect rgb(255, 235, 238)
        Note over NET: Phase 5: å¹¿æ’­
        BG->>NET: broadcast_batch_msg(batch)
        NET->>PEERS: BatchMsg
        PEERS->>PEERS: persist & sign
        PEERS->>NET: SignedBatchInfoMsg
    end

    rect rgb(255, 249, 196)
        Note over BG: Phase 6: è¿‡æœŸç®¡ç†
        BG->>BG: batch_expirations.add((peer, batch_id), expiry)
    end
```

#### generate_batch æ ¸å¿ƒå®ç°

```rust
impl BatchGenerator {
    /// å®šæ—¶ä»»åŠ¡ï¼šå°è¯•ç”Ÿæˆæ–°æ‰¹æ¬¡
    pub async fn tick(&mut self) -> anyhow::Result<()> {
        // ========================================
        // æ­¥éª¤ 1: æ¸…ç†è¿‡æœŸæ‰¹æ¬¡
        // ========================================
        self.expire_batches();

        // ========================================
        // æ­¥éª¤ 2: æ£€æŸ¥åå‹
        // ========================================
        if self.back_pressure.txn_count || self.back_pressure.proof_count {
            counters::BATCH_GENERATOR_BACKPRESSURE.inc();
            debug!("Skipping batch generation due to backpressure");
            return Ok(());
        }

        // ========================================
        // æ­¥éª¤ 3: ç”Ÿæˆæ‰¹æ¬¡
        // ========================================
        if let Some(batch) = self.generate_batch().await? {
            info!(
                "Generated batch {}: {} txns, {} bytes",
                batch.batch_id(),
                batch.num_txns(),
                batch.num_bytes()
            );

            // ========================================
            // æ­¥éª¤ 4: æŒä¹…åŒ–
            // ========================================
            let signed_batch_info = self.batch_writer
                .persist_batch(batch.clone())
                .await?;

            // ========================================
            // æ­¥éª¤ 5: å¹¿æ’­
            // ========================================
            self.network_sender.broadcast_batch_msg(batch.clone()).await;

            // ========================================
            // æ­¥éª¤ 6: æ›´æ–°çŠ¶æ€
            // ========================================
            self.update_state_after_batch_creation(batch);
        }

        Ok(())
    }

    /// ä» Mempool æ‹‰å–äº¤æ˜“å¹¶åˆ›å»ºæ‰¹æ¬¡
    async fn generate_batch(&mut self) -> anyhow::Result<Option<Batch>> {
        let max_txns = self.config.max_batch_txns;
        let max_bytes = self.config.max_batch_bytes;

        // ========================================
        // æ„å»ºæ’é™¤é›†åˆï¼ˆé¿å…é‡å¤æ‹‰å–ï¼‰
        // ========================================
        let excluded_txns: HashSet<_> = self.txns_in_progress_sorted
            .keys()
            .map(|summary| (summary.sender, summary.sequence_number))
            .collect();

        // ========================================
        // ä» Mempool æ‹‰å–
        // ========================================
        let txns = self.mempool_proxy
            .pull_internal(
                max_txns,
                max_bytes,
                excluded_txns,
            )
            .await?;

        if txns.is_empty() {
            return Ok(None);
        }

        // ========================================
        // åˆ›å»ºæ‰¹æ¬¡
        // ========================================
        let batch_id = self.next_batch_id();
        let expiration = self.latest_block_timestamp
            + self.config.batch_expiry_time_usecs;

        let batch = Batch::new(
            batch_id,
            txns,
            self.epoch,
            expiration,
            self.my_peer_id,
            self.config.gas_bucket_start,
        );

        Ok(Some(batch))
    }

    /// ç”Ÿæˆä¸‹ä¸€ä¸ªæ‰¹æ¬¡ ID
    fn next_batch_id(&mut self) -> BatchId {
        let id = self.batch_id.id + 1;
        self.batch_id = BatchId::new(id, self.my_peer_id);
        self.batch_id
    }
}
```

### 3.3 äº¤æ˜“å»é‡æœºåˆ¶

#### å»é‡ç®—æ³•è¯¦è§£

```mermaid
graph TD
    A[pull_txns è¯·æ±‚] --> B[æ„å»º excluded_txns set]

    B --> C[éå† txns_in_progress_sorted]
    C --> D[æå– sender, sequence_number]
    D --> E[æ·»åŠ åˆ° excluded_txns]

    E --> F[Mempool.pull_internal]
    F --> G{æ£€æŸ¥æ¯ä¸ªäº¤æ˜“}

    G -->|excluded_txns åŒ…å«| H[è·³è¿‡è¯¥äº¤æ˜“]
    G -->|ä¸åŒ…å«| I[åŠ å…¥è¿”å›åˆ—è¡¨]

    H --> J[æ£€æŸ¥ä¸‹ä¸€ä¸ª]
    I --> J

    J --> K{æ‰€æœ‰äº¤æ˜“æ£€æŸ¥å®Œ?}
    K -->|å¦| G
    K -->|æ˜¯| L[è¿”å›å»é‡åçš„äº¤æ˜“åˆ—è¡¨]

    style E fill:#fff9c4
    style I fill:#c8e6c9
```

**TransactionSummary è¯¦è§£**ï¼š

```rust
/// äº¤æ˜“æ‘˜è¦ - ç”¨äºå»é‡å’Œæ’åº
#[derive(Clone, Eq, Hash, Ord, PartialEq, PartialOrd)]
struct TransactionSummary {
    /// å‘é€è€…åœ°å€
    sender: AccountAddress,

    /// åºåˆ—å·ï¼ˆç”¨äºæ’åºå’Œå»é‡ï¼‰
    sequence_number: u64,

    /// äº¤æ˜“å“ˆå¸Œï¼ˆç”¨äºç²¾ç¡®åŒ¹é…ï¼‰
    hash: HashValue,
}

impl TransactionSummary {
    pub fn new(sender: AccountAddress, sequence_number: u64, hash: HashValue) -> Self {
        Self {
            sender,
            sequence_number,
            hash,
        }
    }
}

// å®ç° Ord trait ç”¨äº BTreeMap æ’åº
// å…ˆæŒ‰ sender æ’åºï¼Œå†æŒ‰ sequence_number æ’åº
impl Ord for TransactionSummary {
    fn cmp(&self, other: &Self) -> Ordering {
        self.sender.cmp(&other.sender)
            .then_with(|| self.sequence_number.cmp(&other.sequence_number))
            .then_with(|| self.hash.cmp(&other.hash))
    }
}
```

**å¹¶è¡Œè®¡ç®—ä¼˜åŒ–**ï¼š

```rust
impl BatchGenerator {
    /// æ’å…¥è¿œç¨‹æ‰¹æ¬¡ï¼ˆæ¥è‡ªå…¶ä»–éªŒè¯è€…ï¼‰
    pub fn insert_batch(
        &mut self,
        author: PeerId,
        batch_id: BatchId,
        txns: Vec<SignedTransaction>,
        expiry_time: u64,
    ) {
        // ========================================
        // å¹¶è¡Œè®¡ç®—äº¤æ˜“æ‘˜è¦ï¼ˆåˆ©ç”¨å¤šæ ¸ï¼‰
        // ========================================
        let txns_in_progress: Vec<_> = txns
            .par_iter()
            .with_min_len(optimal_min_len(txns.len(), 32))
            .map(|txn| {
                let summary = TransactionSummary::new(
                    txn.sender(),
                    txn.sequence_number(),
                    txn.committed_hash(),
                );

                let info = TransactionInProgress {
                    gas_unit_price: txn.gas_unit_price(),
                    insertion_time: Instant::now(),
                };

                (summary, info)
            })
            .collect();

        // ========================================
        // æ‰¹é‡æ’å…¥ï¼ˆé¿å…é‡å¤é”ï¼‰
        // ========================================
        for (summary, info) in txns_in_progress {
            self.txns_in_progress_sorted
                .entry(summary)
                .or_insert(info);
        }

        // ========================================
        // è®°å½•æ‰¹æ¬¡ä¿¡æ¯
        // ========================================
        let batch_info = BatchInProgress {
            batch_id,
            num_txns: txns.len(),
            num_bytes: bcs::serialized_size(&txns).unwrap_or(0),
            creation_time: Instant::now(),
        };

        self.batches_in_progress.insert((author, batch_id), batch_info);

        // ========================================
        // æ·»åŠ åˆ°è¿‡æœŸé˜Ÿåˆ—
        // ========================================
        self.batch_expirations.add((author, batch_id), expiry_time);
    }
}
```

### 3.4 è¿‡æœŸç®¡ç†

#### TimeExpirations æœºåˆ¶

```mermaid
classDiagram
    class TimeExpirations~T~ {
        -BTreeMap~u64,Vec~T~~ expirations
        +add(item: T, expiry_time: u64) void
        +expire(now: u64) Vec~T~
        +remove(item: &T) void
    }

    class BatchGenerator {
        -TimeExpirations batch_expirations
        +expire_batches() void
        +cleanup_batch(peer, batch_id) void
    }

    BatchGenerator --> TimeExpirations
```

**ä»£ç å®ç°**ï¼š

```rust
// src/quorum_store/utils/time_expiration.rs

pub struct TimeExpirations<T> {
    /// è¿‡æœŸæ—¶é—´ -> é¡¹ç›®åˆ—è¡¨
    expirations: BTreeMap<u64, Vec<T>>,
}

impl<T: Clone + Eq + Hash> TimeExpirations<T> {
    pub fn new() -> Self {
        Self {
            expirations: BTreeMap::new(),
        }
    }

    /// æ·»åŠ é¡¹ç›®åˆ°è¿‡æœŸé˜Ÿåˆ—
    pub fn add(&mut self, item: T, expiry_time: u64) {
        self.expirations
            .entry(expiry_time)
            .or_insert_with(Vec::new)
            .push(item);
    }

    /// è·å–å¹¶ç§»é™¤æ‰€æœ‰è¿‡æœŸé¡¹ç›®
    pub fn expire(&mut self, now: u64) -> Vec<T> {
        let mut expired = Vec::new();

        // ä½¿ç”¨ split_off åˆ†å‰² BTreeMap
        let expired_map = self.expirations.split_off(&(now + 1));
        let remaining = std::mem::replace(&mut self.expirations, expired_map);

        // æ”¶é›†æ‰€æœ‰è¿‡æœŸé¡¹ç›®
        for (_, items) in remaining {
            expired.extend(items);
        }

        expired
    }

    /// ç§»é™¤ç‰¹å®šé¡¹ç›®
    pub fn remove(&mut self, item: &T) {
        for items in self.expirations.values_mut() {
            items.retain(|i| i != item);
        }
    }
}

// BatchGenerator ä¸­çš„ä½¿ç”¨
impl BatchGenerator {
    /// æ¸…ç†è¿‡æœŸæ‰¹æ¬¡
    fn expire_batches(&mut self) {
        let now = self.latest_block_timestamp;
        let expired = self.batch_expirations.expire(now);

        for (author, batch_id) in expired {
            self.cleanup_batch(author, batch_id);
        }

        counters::BATCH_EXPIRED_COUNT.inc_by(expired.len() as u64);
    }

    /// æ¸…ç†å•ä¸ªæ‰¹æ¬¡
    fn cleanup_batch(&mut self, author: PeerId, batch_id: BatchId) {
        // ç§»é™¤æ‰¹æ¬¡è®°å½•
        if let Some(batch_info) = self.batches_in_progress.remove(&(author, batch_id)) {
            info!(
                "Expired batch {}: {} txns",
                batch_id,
                batch_info.num_txns
            );
        }

        // é‡Šæ”¾äº¤æ˜“è·Ÿè¸ªï¼ˆéœ€è¦è¯»å–äº¤æ˜“åˆ—è¡¨ï¼‰
        // å®é™…å®ç°ä¸­å¯èƒ½éœ€è¦ä» DB è¯»å–æ‰¹æ¬¡è¯¦æƒ…
    }
}
```

#### è¿‡æœŸæµç¨‹å¯è§†åŒ–

```mermaid
gantt
    title Batch è¿‡æœŸæ—¶é—´çº¿
    dateFormat X
    axisFormat %L

    section Batch Lifecycle
    åˆ›å»º (t=0)             :milestone, m1, 0, 0
    å­˜æ´»æœŸ (60s)           :active, a1, 0, 60000
    è¿‡æœŸæ£€æŸ¥ (t=60s)       :crit, c1, 60000, 100
    æ¸…ç† (t=60.1s)         :done, d1, 60100, 500

    section å®šæ—¶æ£€æŸ¥
    Tick 1 (t=0)           :milestone, t1, 0, 0
    Tick 2 (t=0.1s)        :milestone, t2, 100, 0
    ...                    :milestone, t3, 30000, 0
    Tick N (t=60s)         :crit, t4, 60000, 0
```

---

## 4. BatchStore å­˜å‚¨å±‚è¯¦è§£

### 4.1 ä¸‰çº§å­˜å‚¨æ¶æ„

#### æ¶æ„è¯¦å›¾

```mermaid
graph TB
    subgraph "Level 1: å†…å­˜ç¼“å­˜ (Fast)"
        Cache[DashMap<br/>â”â”â”â”â”â”â”â”â”â”<br/>Key: BatchKey<br/>Value: PersistedBatch<br/>â”â”â”â”â”â”â”â”â”â”<br/>Size: 120MB é»˜è®¤]
    end

    subgraph "Level 2: RocksDB (Durable)"
        DB[(RocksDB<br/>â”â”â”â”â”â”â”â”â”â”<br/>Column: batches<br/>â”â”â”â”â”â”â”â”â”â”<br/>Size: 960MB é»˜è®¤)]
    end

    subgraph "Level 3: é…é¢ç®¡ç†"
        QM[QuotaManager<br/>â”â”â”â”â”â”â”â”â”â”<br/>Memory: 120MB<br/>DB: 960MB<br/>Batch Count: 2500]
    end

    A[å†™å…¥è¯·æ±‚] -->|1. æ£€æŸ¥é…é¢| QM
    QM -->|2. åˆ†é…æˆåŠŸ| B{å­˜å‚¨æ¨¡å¼å†³ç­–}

    B -->|Memory + DB| Cache
    B -->|DB Only| DB

    Cache -->|3a. å†™å…¥å†…å­˜| Cache
    Cache -->|3b. å†™å…¥ç£ç›˜| DB

    C[è¯»å–è¯·æ±‚] -->|1. æŸ¥è¯¢ç¼“å­˜| Cache
    Cache -->|Hit| D[è¿”å›æ•°æ®]
    Cache -->|Miss| DB
    DB -->|2. ä»ç£ç›˜è¯»å–| DB
    DB -->|3. åŠ è½½åˆ°ç¼“å­˜| Cache
    Cache --> D

    style Cache fill:#4caf50
    style DB fill:#2196f3
    style QM fill:#ff9800
```

#### å­˜å‚¨æ¨¡å¼æšä¸¾

```mermaid
classDiagram
    class StorageMode {
        <<enumeration>>
        MemoryAndPersisted
        PersistedOnly
    }

    class PersistedBatch {
        +Batch batch
        +StorageMode storage_mode
        +Instant persist_time
    }

    class BatchStore {
        +DashMap~BatchKey,PersistedBatch~ db_cache
        +Arc~QuorumStoreDB~ db
        +QuotaManager quota_manager
        +persist_batch(batch) Result
        +get_batch(key) Option~Batch~
    }

    BatchStore --> StorageMode
    BatchStore --> PersistedBatch
```

### 4.2 é…é¢ç®¡ç†æœºåˆ¶

#### QuotaManager å®Œæ•´å®ç°

```rust
// src/quorum_store/batch_store.rs

pub struct QuotaManager {
    // ========================================
    // å‰©ä½™é…é¢
    // ========================================
    /// å‰©ä½™å†…å­˜é…é¢ï¼ˆå­—èŠ‚ï¼‰
    memory_balance: usize,

    /// å‰©ä½™ç£ç›˜é…é¢ï¼ˆå­—èŠ‚ï¼‰
    db_balance: usize,

    /// å‰©ä½™æ‰¹æ¬¡æ•°é…é¢
    batch_balance: usize,

    // ========================================
    // æ€»é…é¢é™åˆ¶
    // ========================================
    memory_quota: usize,      // é»˜è®¤: 120MB
    db_quota: usize,          // é»˜è®¤: 960MB
    batch_quota: usize,       // é»˜è®¤: 2500
}

impl QuotaManager {
    pub fn new(
        memory_quota: usize,
        db_quota: usize,
        batch_quota: usize,
    ) -> Self {
        Self {
            memory_balance: memory_quota,
            db_balance: db_quota,
            batch_balance: batch_quota,
            memory_quota,
            db_quota,
            batch_quota,
        }
    }

    /// å°è¯•åˆ†é…é…é¢
    pub fn update_quota(
        &mut self,
        num_bytes: usize,
    ) -> anyhow::Result<StorageMode> {
        // ========================================
        // æ­¥éª¤ 1: æ£€æŸ¥æ‰¹æ¬¡æ•°é…é¢
        // ========================================
        if self.batch_balance == 0 {
            counters::EXCEEDED_BATCH_QUOTA_COUNT.inc();
            bail!(
                "Batch quota exceeded: 0 / {}",
                self.batch_quota
            );
        }

        // ========================================
        // æ­¥éª¤ 2: æ£€æŸ¥ç£ç›˜é…é¢
        // ========================================
        if self.db_balance < num_bytes {
            counters::EXCEEDED_STORAGE_QUOTA_COUNT.inc();
            bail!(
                "Storage quota exceeded: {} < {} bytes",
                self.db_balance,
                num_bytes
            );
        }

        // ========================================
        // æ­¥éª¤ 3: æ‰£é™¤ç£ç›˜é…é¢å’Œæ‰¹æ¬¡æ•°
        // ========================================
        self.batch_balance -= 1;
        self.db_balance -= num_bytes;

        // ========================================
        // æ­¥éª¤ 4: å†³å®šå­˜å‚¨æ¨¡å¼
        // ========================================
        if self.memory_balance >= num_bytes {
            // å†…å­˜å……è¶³ï¼Œä½¿ç”¨å†…å­˜ + ç£ç›˜
            self.memory_balance -= num_bytes;

            counters::BATCH_STORED_IN_MEMORY.inc();

            Ok(StorageMode::MemoryAndPersisted)
        } else {
            // å†…å­˜ä¸è¶³ï¼Œä»…ä½¿ç”¨ç£ç›˜
            counters::BATCH_STORED_IN_DB_ONLY.inc();

            Ok(StorageMode::PersistedOnly)
        }
    }

    /// é‡Šæ”¾é…é¢
    pub fn free_quota(
        &mut self,
        num_bytes: usize,
        storage_mode: StorageMode,
    ) {
        self.batch_balance += 1;
        self.db_balance += num_bytes;

        if matches!(storage_mode, StorageMode::MemoryAndPersisted) {
            self.memory_balance += num_bytes;
        }

        counters::BATCH_QUOTA_FREED.inc();
    }

    /// è·å–é…é¢ä½¿ç”¨ç‡
    pub fn utilization(&self) -> QuotaUtilization {
        QuotaUtilization {
            memory_usage: 1.0 - (self.memory_balance as f64 / self.memory_quota as f64),
            db_usage: 1.0 - (self.db_balance as f64 / self.db_quota as f64),
            batch_usage: 1.0 - (self.batch_balance as f64 / self.batch_quota as f64),
        }
    }
}

#[derive(Debug)]
pub struct QuotaUtilization {
    pub memory_usage: f64,  // 0.0 - 1.0
    pub db_usage: f64,
    pub batch_usage: f64,
}
```

#### é…é¢ä½¿ç”¨æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant BG as BatchGenerator
    participant BS as BatchStore
    participant QM as QuotaManager
    participant Cache as DashMap Cache
    participant DB as RocksDB

    Note over BG,DB: â•â•â•â•â•â•â•â•â•â• é…é¢åˆ†é…æµç¨‹ â•â•â•â•â•â•â•â•â•â•

    BG->>BS: persist_batch(batch)
    BS->>BS: num_bytes = batch.num_bytes()

    rect rgb(225, 245, 255)
        Note over QM: é…é¢æ£€æŸ¥
        BS->>QM: update_quota(num_bytes)

        QM->>QM: check batch_balance
        alt batch_balance == 0
            QM->>BS: Error: Batch quota exceeded
            BS->>BG: Error
        end

        QM->>QM: check db_balance
        alt db_balance < num_bytes
            QM->>BS: Error: Storage quota exceeded
            BS->>BG: Error
        end
    end

    rect rgb(255, 249, 196)
        Note over QM: æ‰£é™¤é…é¢
        QM->>QM: batch_balance -= 1
        QM->>QM: db_balance -= num_bytes

        alt memory_balance >= num_bytes
            QM->>QM: memory_balance -= num_bytes
            QM->>BS: StorageMode::MemoryAndPersisted
        else
            QM->>BS: StorageMode::PersistedOnly
        end
    end

    rect rgb(200, 230, 201)
        Note over Cache,DB: æŒä¹…åŒ–
        alt MemoryAndPersisted
            BS->>Cache: insert(key, batch)
            BS->>DB: save(key, batch)
        else PersistedOnly
            BS->>DB: save(key, batch)
        end
    end

    BS->>BG: Ok(SignedBatchInfo)
```

### 4.3 æ‰¹æ¬¡æŒä¹…åŒ–

#### BatchStore å®Œæ•´ç»“æ„

```rust
pub struct BatchStore {
    // ========================================
    // å­˜å‚¨
    // ========================================
    /// å†…å­˜ç¼“å­˜
    db_cache: Arc<DashMap<BatchKey, PersistedBatch>>,

    /// æŒä¹…åŒ–å­˜å‚¨
    db: Arc<dyn QuorumStoreStorage>,

    // ========================================
    // é…é¢ç®¡ç†
    // ========================================
    quota_manager: Arc<Mutex<QuotaManager>>,

    // ========================================
    // ç­¾åå™¨
    // ========================================
    signer: ValidatorSigner,

    // ========================================
    // Epoch ä¿¡æ¯
    // ========================================
    epoch: u64,
}

impl BatchStore {
    /// æŒä¹…åŒ–æ‰¹æ¬¡
    pub async fn persist_batch(
        &self,
        batch: Batch,
    ) -> anyhow::Result<SignedBatchInfo> {
        let num_bytes = batch.num_bytes();
        let batch_key = BatchKey::new(batch.author(), batch.batch_id());

        // ========================================
        // æ­¥éª¤ 1: åˆ†é…é…é¢
        // ========================================
        let storage_mode = self.quota_manager
            .lock()
            .update_quota(num_bytes)?;

        info!(
            "Persisting batch {}: {} txns, {} bytes, mode: {:?}",
            batch.batch_id(),
            batch.num_txns(),
            num_bytes,
            storage_mode
        );

        // ========================================
        // æ­¥éª¤ 2: ä¿å­˜åˆ° RocksDB
        // ========================================
        self.db.save_batch(batch_key, &batch).await?;

        // ========================================
        // æ­¥éª¤ 3: å¯é€‰åœ°åŠ å…¥å†…å­˜ç¼“å­˜
        // ========================================
        if matches!(storage_mode, StorageMode::MemoryAndPersisted) {
            let persisted_batch = PersistedBatch {
                batch: batch.clone(),
                storage_mode,
                persist_time: Instant::now(),
            };

            self.db_cache.insert(batch_key, persisted_batch);
        }

        // ========================================
        // æ­¥éª¤ 4: ç”Ÿæˆ BatchInfo å¹¶ç­¾å
        // ========================================
        let batch_info = BatchInfo::new(
            batch.author(),
            batch.batch_id(),
            batch.epoch(),
            batch.expiration_usecs(),
            batch.compute_transaction_hashes(),
            batch.gas_bucket_start(),
        );

        let signature = self.signer.sign(&batch_info.digest())?;

        let signed_batch_info = SignedBatchInfo::new(
            batch_info,
            self.signer.author(),
            signature,
        );

        counters::BATCH_PERSISTED.inc();
        counters::BATCH_PERSISTED_BYTES.inc_by(num_bytes as u64);

        Ok(signed_batch_info)
    }

    /// è·å–æ‰¹æ¬¡
    pub async fn get_batch(
        &self,
        key: &BatchKey,
    ) -> anyhow::Result<Option<Batch>> {
        // ========================================
        // æ­¥éª¤ 1: å°è¯•ä»ç¼“å­˜è¯»å–
        // ========================================
        if let Some(persisted) = self.db_cache.get(key) {
            counters::BATCH_CACHE_HIT.inc();
            return Ok(Some(persisted.batch.clone()));
        }

        counters::BATCH_CACHE_MISS.inc();

        // ========================================
        // æ­¥éª¤ 2: ä» RocksDB è¯»å–
        // ========================================
        let batch = self.db.get_batch(key).await?;

        // ========================================
        // æ­¥éª¤ 3: åŠ è½½åˆ°ç¼“å­˜ï¼ˆå¦‚æœæœ‰ç©ºé—´ï¼‰
        // ========================================
        if let Some(ref batch) = batch {
            let num_bytes = batch.num_bytes();

            // å°è¯•åˆ†é…å†…å­˜é…é¢
            if let Ok(mut quota) = self.quota_manager.try_lock() {
                if quota.memory_balance >= num_bytes {
                    quota.memory_balance -= num_bytes;

                    let persisted_batch = PersistedBatch {
                        batch: batch.clone(),
                        storage_mode: StorageMode::MemoryAndPersisted,
                        persist_time: Instant::now(),
                    };

                    self.db_cache.insert(*key, persisted_batch);
                }
            }
        }

        Ok(batch)
    }
}
```

### 4.4 ç­¾åä¸éªŒè¯

#### ç­¾åæµç¨‹

```mermaid
graph TD
    A[Batch åˆ›å»º] --> B[è®¡ç®— transaction_hashes]
    B --> C[æ„é€  BatchInfo]

    C --> D[BatchInfo.digest]
    D --> E[ValidatorSigner.sign]

    E --> F[ç”Ÿæˆ bls12381::Signature]
    F --> G[æ„é€  SignedBatchInfo]

    G --> H[å¹¿æ’­ SignedBatchInfoMsg]

    H --> I[å…¶ä»–éªŒè¯è€…æ¥æ”¶]
    I --> J[éªŒè¯ç­¾å]

    J --> K{ç­¾åæœ‰æ•ˆ?}
    K -->|æ˜¯| L[æ·»åŠ åˆ° signature_aggregator]
    K -->|å¦| M[ä¸¢å¼ƒ]

    style D fill:#fff9c4
    style E fill:#e1f5ff
    style K fill:#c8e6c9
```

**éªŒè¯ä»£ç **ï¼š

```rust
impl SignedBatchInfo {
    /// éªŒè¯ç­¾å
    pub fn verify(
        &self,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<()> {
        // è®¡ç®—æ¶ˆæ¯å“ˆå¸Œ
        let message = self.info.digest();

        // éªŒè¯ç­¾å
        verifier.verify_signature(
            self.signer,
            &message,
            &self.signature,
        )?;

        Ok(())
    }
}
```

---

## 5. ProofCoordinator è¯æ˜åè°ƒå™¨

### 5.1 ç­¾åæ”¶é›†æœºåˆ¶

#### ProofCoordinator ç»“æ„

```rust
// src/quorum_store/proof_coordinator.rs

pub struct ProofCoordinator {
    // ========================================
    // Epoch ä¿¡æ¯
    // ========================================
    epoch: u64,
    my_peer_id: PeerId,

    // ========================================
    // ç­¾åèšåˆå™¨
    // ========================================
    /// BatchId -> ProofAggregator
    proof_aggregators: HashMap<BatchId, ProofAggregator>,

    // ========================================
    // æ‰¹æ¬¡å­˜å‚¨
    // ========================================
    batch_store: Arc<BatchStore>,

    // ========================================
    // éªŒè¯å™¨
    // ========================================
    validator_verifier: ValidatorVerifier,

    // ========================================
    // ç½‘ç»œ
    // ========================================
    network_sender: QuorumStoreNetworkSender,

    // ========================================
    // é…ç½®
    // ========================================
    config: QuorumStoreConfig,
}

/// å•ä¸ª Batch çš„ç­¾åèšåˆå™¨
struct ProofAggregator {
    batch_info: BatchInfo,

    /// Author -> Signature
    signatures: HashMap<Author, bls12381::Signature>,

    /// å½“å‰æŠ•ç¥¨æƒé‡
    voting_power: u64,

    /// åˆ›å»ºæ—¶é—´
    creation_time: Instant,
}
```

#### ç­¾åæ”¶é›†æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant V1 as Validator 1 (Local)
    participant PC as ProofCoordinator
    participant BS as BatchStore
    participant NET as Network
    participant V2 as Validator 2
    participant V3 as Validator 3
    participant V4 as Validator 4
    participant PM as ProofManager

    Note over V1,PM: â•â•â•â•â•â•â•â•â•â• ç­¾åæ”¶é›†å®Œæ•´æµç¨‹ â•â•â•â•â•â•â•â•â•â•

    rect rgb(225, 245, 255)
        Note over V1,BS: Phase 1: æœ¬åœ°æ‰¹æ¬¡æŒä¹…åŒ–
        V1->>BS: persist_batch(batch)
        BS->>BS: save to DB + cache
        BS->>BS: sign BatchInfo
        BS->>V1: SignedBatchInfo (local)
    end

    rect rgb(255, 249, 196)
        Note over NET: Phase 2: å¹¿æ’­æ‰¹æ¬¡
        V1->>NET: broadcast BatchMsg(batch)
        NET->>V2: BatchMsg
        NET->>V3: BatchMsg
        NET->>V4: BatchMsg
    end

    rect rgb(243, 229, 245)
        Note over V2: Phase 3: è¿œç¨‹éªŒè¯è€…å¤„ç†
        V2->>V2: receive BatchMsg
        V2->>BS: persist remote batch
        BS->>BS: verify & save
        V2->>V2: sign BatchInfo
        V2->>NET: SignedBatchInfoMsg

        Note over V3: åŒæ ·å¤„ç†
        V3->>NET: SignedBatchInfoMsg

        Note over V4: åŒæ ·å¤„ç†
        V4->>NET: SignedBatchInfoMsg
    end

    rect rgb(200, 230, 201)
        Note over PC: Phase 4: æ”¶é›†ç­¾å
        NET->>PC: SignedBatchInfoMsg (from V2)
        PC->>PC: verify signature
        PC->>PC: add to aggregator
        PC->>PC: voting_power += V2.power

        NET->>PC: SignedBatchInfoMsg (from V3)
        PC->>PC: add signature
        PC->>PC: voting_power += V3.power

        NET->>PC: SignedBatchInfoMsg (from V4)
        PC->>PC: add signature
        PC->>PC: voting_power += V4.power
    end

    rect rgb(255, 235, 238)
        Note over PC: Phase 5: è¾¾åˆ° Quorum
        PC->>PC: voting_power >= 2f+1?
        PC->>PC: aggregate signatures
        PC->>PC: construct ProofOfStore
        PC->>PM: notify proof ready
    end
```

### 5.2 èšåˆç­¾åç®—æ³•

#### èšåˆæµç¨‹è¯¦å›¾

```mermaid
graph TD
    A[æ”¶åˆ° SignedBatchInfoMsg] --> B{éªŒè¯ç­¾å}
    B -->|å¤±è´¥| C[ä¸¢å¼ƒæ¶ˆæ¯]
    B -->|æˆåŠŸ| D{ProofAggregator å­˜åœ¨?}

    D -->|å¦| E[åˆ›å»º ProofAggregator]
    D -->|æ˜¯| F[è·å– ProofAggregator]

    E --> G[æ·»åŠ ç­¾å]
    F --> G

    G --> H[æ›´æ–° voting_power]
    H --> I{voting_power >= quorum?}

    I -->|å¦| J[ç»§ç»­ç­‰å¾…]
    I -->|æ˜¯| K[èšåˆç­¾å]

    K --> L[BLS èšåˆç®—æ³•]
    L --> M[ç”Ÿæˆ AggregateSignature]

    M --> N[æ„é€  ProofOfStore]
    N --> O[éªŒè¯ ProofOfStore]

    O --> P{éªŒè¯é€šè¿‡?}
    P -->|æ˜¯| Q[å‘é€åˆ° ProofManager]
    P -->|å¦| R[ä¸¢å¼ƒ]

    style B fill:#fff9c4
    style K fill:#e1f5ff
    style O fill:#c8e6c9
```

#### ProofAggregator å®ç°

```rust
impl ProofAggregator {
    pub fn new(batch_info: BatchInfo) -> Self {
        Self {
            batch_info,
            signatures: HashMap::new(),
            voting_power: 0,
            creation_time: Instant::now(),
        }
    }

    /// æ·»åŠ ç­¾å
    pub fn add_signature(
        &mut self,
        author: Author,
        signature: bls12381::Signature,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<bool> {
        // ========================================
        // æ­¥éª¤ 1: æ£€æŸ¥é‡å¤
        // ========================================
        if self.signatures.contains_key(&author) {
            return Ok(false);
        }

        // ========================================
        // æ­¥éª¤ 2: éªŒè¯ç­¾å
        // ========================================
        let message = self.batch_info.digest();
        verifier.verify_signature(author, &message, &signature)?;

        // ========================================
        // æ­¥éª¤ 3: æ·»åŠ ç­¾å
        // ========================================
        self.signatures.insert(author, signature);

        // ========================================
        // æ­¥éª¤ 4: æ›´æ–°æŠ•ç¥¨æƒé‡
        // ========================================
        let author_power = verifier.get_voting_power(&author)?;
        self.voting_power += author_power;

        info!(
            "Added signature for batch {}: {} / {} voting power",
            self.batch_info.batch_id(),
            self.voting_power,
            verifier.total_voting_power()
        );

        // ========================================
        // æ­¥éª¤ 5: æ£€æŸ¥æ˜¯å¦è¾¾åˆ° quorum
        // ========================================
        Ok(self.voting_power >= verifier.quorum_voting_power())
    }

    /// èšåˆç­¾åå¹¶ç”Ÿæˆ ProofOfStore
    pub fn aggregate(
        self,
        verifier: &ValidatorVerifier,
    ) -> anyhow::Result<ProofOfStore> {
        // ========================================
        // æ­¥éª¤ 1: æå–ç­¾ååˆ—è¡¨
        // ========================================
        let signatures: Vec<_> = self.signatures.values().cloned().collect();

        // ========================================
        // æ­¥éª¤ 2: BLS èšåˆç­¾å
        // ========================================
        let aggregated_sig = bls12381::Signature::aggregate(&signatures)?;

        // ========================================
        // æ­¥éª¤ 3: æ„é€  AggregateSignature
        // ========================================
        let signers: Vec<_> = self.signatures.keys().cloned().collect();
        let multi_signature = AggregateSignature::new(
            signers,
            aggregated_sig,
        );

        // ========================================
        // æ­¥éª¤ 4: æ„é€  ProofOfStore
        // ========================================
        let proof = ProofOfStore::new(
            self.batch_info,
            multi_signature,
        );

        // ========================================
        // æ­¥éª¤ 5: éªŒè¯ ProofOfStore
        // ========================================
        proof.verify(verifier)?;

        info!("Generated ProofOfStore for batch {}", proof.batch_id());

        Ok(proof)
    }
}
```

### 5.3 ProofOfStore ç”Ÿæˆ

#### å®Œæ•´æµç¨‹å®ç°

```rust
impl ProofCoordinator {
    /// å¤„ç† SignedBatchInfoMsg
    pub async fn handle_signed_batch_info_msg(
        &mut self,
        msg: SignedBatchInfoMsg,
    ) -> anyhow::Result<()> {
        let signed_batch_info = msg.signed_batch_info();
        let batch_id = signed_batch_info.info().batch_id();

        // ========================================
        // æ­¥éª¤ 1: éªŒè¯ç­¾å
        // ========================================
        signed_batch_info.verify(&self.validator_verifier)?;

        info!(
            "Received SignedBatchInfo for batch {} from {}",
            batch_id,
            signed_batch_info.signer()
        );

        // ========================================
        // æ­¥éª¤ 2: è·å–æˆ–åˆ›å»º ProofAggregator
        // ========================================
        let aggregator = self.proof_aggregators
            .entry(batch_id)
            .or_insert_with(|| {
                ProofAggregator::new(signed_batch_info.info().clone())
            });

        // ========================================
        // æ­¥éª¤ 3: æ·»åŠ ç­¾å
        // ========================================
        let reached_quorum = aggregator.add_signature(
            signed_batch_info.signer(),
            signed_batch_info.signature().clone(),
            &self.validator_verifier,
        )?;

        // ========================================
        // æ­¥éª¤ 4: æ£€æŸ¥æ˜¯å¦è¾¾åˆ° quorum
        // ========================================
        if reached_quorum {
            info!("Reached quorum for batch {}", batch_id);

            // ç§»é™¤ aggregatorï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
            let aggregator = self.proof_aggregators.remove(&batch_id).unwrap();

            // èšåˆç­¾å
            let proof = aggregator.aggregate(&self.validator_verifier)?;

            // å‘é€åˆ° ProofManager
            self.send_proof_to_manager(proof).await?;
        }

        Ok(())
    }

    async fn send_proof_to_manager(
        &self,
        proof: ProofOfStore,
    ) -> anyhow::Result<()> {
        // é€šè¿‡ channel å‘é€ç»™ ProofManager
        // å…·ä½“å®ç°ä¾èµ–äºç³»ç»Ÿæ¶æ„
        Ok(())
    }
}
```

---

## 6. ProofManager è¯æ˜ç®¡ç†å™¨

### 6.1 Proof ç¼“å­˜ç®¡ç†

#### ProofManager ç»“æ„

```rust
// src/quorum_store/proof_manager.rs

pub struct ProofManager {
    // ========================================
    // Proof é˜Ÿåˆ—ï¼ˆæŒ‰ gas ä¼˜å…ˆçº§ï¼‰
    // ========================================
    proof_queue: ProofQueue,

    // ========================================
    // å·²æäº¤çš„ Proofs
    // ========================================
    /// Round -> Vec<ProofOfStore>
    committed_proofs: BTreeMap<Round, Vec<ProofOfStore>>,

    // ========================================
    // é…ç½®
    // ========================================
    config: QuorumStoreConfig,

    // ========================================
    // ç»Ÿè®¡
    // ========================================
    total_proofs_generated: u64,
    total_proofs_pulled: u64,
}

/// Proof ä¼˜å…ˆé˜Ÿåˆ—
struct ProofQueue {
    /// Gas bucket -> Vec<ProofOfStore>
    proofs_by_gas: BTreeMap<u64, Vec<ProofOfStore>>,

    /// æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    total_bytes: usize,

    /// æœ€å¤§å¤§å°é™åˆ¶
    max_bytes: usize,
}
```

#### ProofQueue å®ç°

```mermaid
classDiagram
    class ProofQueue {
        -BTreeMap~u64,Vec~ProofOfStore~~ proofs_by_gas
        -usize total_bytes
        -usize max_bytes
        +push(proof) Result
        +pull(max_bytes, excluded) Vec~ProofOfStore~
        +clean_expired(now) void
    }

    class ProofManager {
        -ProofQueue proof_queue
        +add_proof(proof) Result
        +pull_proofs(params) Vec~ProofOfStore~
        +handle_commit_notification(commit) void
    }

    ProofManager --> ProofQueue
```

**ä»£ç å®ç°**ï¼š

```rust
impl ProofQueue {
    pub fn new(max_bytes: usize) -> Self {
        Self {
            proofs_by_gas: BTreeMap::new(),
            total_bytes: 0,
            max_bytes,
        }
    }

    /// æ·»åŠ  Proof
    pub fn push(&mut self, proof: ProofOfStore) -> anyhow::Result<()> {
        let proof_bytes = proof.num_bytes();

        // ========================================
        // æ£€æŸ¥å®¹é‡
        // ========================================
        if self.total_bytes + proof_bytes > self.max_bytes {
            counters::PROOF_QUEUE_OVERFLOW.inc();
            bail!("Proof queue full: {} bytes", self.total_bytes);
        }

        // ========================================
        // æ·»åŠ åˆ°å¯¹åº”çš„ gas bucket
        // ========================================
        let gas_bucket = proof.gas_bucket_start();
        self.proofs_by_gas
            .entry(gas_bucket)
            .or_insert_with(Vec::new)
            .push(proof);

        self.total_bytes += proof_bytes;

        counters::PROOF_QUEUE_SIZE_BYTES.set(self.total_bytes as i64);

        Ok(())
    }

    /// æ‹‰å– Proofsï¼ˆæŒ‰ gas ä»é«˜åˆ°ä½ï¼‰
    pub fn pull(
        &mut self,
        max_bytes: usize,
        excluded_batches: &HashSet<BatchId>,
    ) -> Vec<ProofOfStore> {
        let mut selected = Vec::new();
        let mut selected_bytes = 0;

        // ========================================
        // ä»æœ€é«˜ gas bucket å¼€å§‹æ‹‰å–
        // ========================================
        let mut buckets_to_remove = Vec::new();

        for (gas_bucket, proofs) in self.proofs_by_gas.iter_mut().rev() {
            let mut remaining = Vec::new();

            for proof in proofs.drain(..) {
                // è·³è¿‡å·²æ’é™¤çš„æ‰¹æ¬¡
                if excluded_batches.contains(&proof.batch_id()) {
                    continue;
                }

                let proof_bytes = proof.num_bytes();

                // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
                if selected_bytes + proof_bytes > max_bytes {
                    remaining.push(proof);
                    continue;
                }

                // æ·»åŠ åˆ°é€‰æ‹©åˆ—è¡¨
                selected.push(proof);
                selected_bytes += proof_bytes;
            }

            if remaining.is_empty() {
                buckets_to_remove.push(*gas_bucket);
            } else {
                *proofs = remaining;
            }

            // å·²è¾¾åˆ°é™åˆ¶ï¼Œåœæ­¢æ‹‰å–
            if selected_bytes >= max_bytes {
                break;
            }
        }

        // ç§»é™¤ç©ºçš„ buckets
        for gas_bucket in buckets_to_remove {
            self.proofs_by_gas.remove(&gas_bucket);
        }

        // æ›´æ–°æ€»å¤§å°
        self.total_bytes -= selected_bytes;

        counters::PROOF_QUEUE_SIZE_BYTES.set(self.total_bytes as i64);
        counters::PROOFS_PULLED.inc_by(selected.len() as u64);

        selected
    }

    /// æ¸…ç†è¿‡æœŸ Proofs
    pub fn clean_expired(&mut self, now: u64) {
        let mut total_removed = 0;
        let mut removed_bytes = 0;

        for proofs in self.proofs_by_gas.values_mut() {
            let original_len = proofs.len();

            proofs.retain(|proof| {
                let not_expired = proof.expiration() > now;

                if !not_expired {
                    removed_bytes += proof.num_bytes();
                }

                not_expired
            });

            total_removed += original_len - proofs.len();
        }

        self.total_bytes -= removed_bytes;

        counters::PROOFS_EXPIRED.inc_by(total_removed as u64);
    }
}
```

### 6.2 æ‹‰å–ç­–ç•¥

#### pull_proofs å®Œæ•´å®ç°

```rust
impl ProofManager {
    /// ä¸º ProposalGenerator æ‹‰å– Proofs
    pub fn pull_proofs(
        &mut self,
        max_txns: u64,
        max_bytes: u64,
        excluded_batches: HashSet<BatchId>,
    ) -> Vec<ProofOfStore> {
        info!(
            "Pulling proofs: max_txns={}, max_bytes={}, excluded={}",
            max_txns,
            max_bytes,
            excluded_batches.len()
        );

        // ========================================
        // æ­¥éª¤ 1: æ¸…ç†è¿‡æœŸ Proofs
        // ========================================
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_micros() as u64;

        self.proof_queue.clean_expired(now);

        // ========================================
        // æ­¥éª¤ 2: ä»é˜Ÿåˆ—æ‹‰å–
        // ========================================
        let proofs = self.proof_queue.pull(max_bytes as usize, &excluded_batches);

        // ========================================
        // æ­¥éª¤ 3: è¿‡æ»¤äº¤æ˜“æ•°é™åˆ¶
        // ========================================
        let mut selected = Vec::new();
        let mut total_txns = 0u64;

        for proof in proofs {
            let proof_txns = proof.num_txns() as u64;

            if total_txns + proof_txns > max_txns {
                break;
            }

            selected.push(proof);
            total_txns += proof_txns;
        }

        self.total_proofs_pulled += selected.len() as u64;

        counters::PROOFS_PULLED_FOR_PROPOSAL.inc_by(selected.len() as u64);
        counters::PROOFS_PULLED_TXNS.inc_by(total_txns);

        info!("Pulled {} proofs with {} txns", selected.len(), total_txns);

        selected
    }
}
```

#### æ‹‰å–æµç¨‹å¯è§†åŒ–

```mermaid
sequenceDiagram
    autonumber
    participant PG as ProposalGenerator
    participant PM as ProofManager
    participant PQ as ProofQueue

    Note over PG,PQ: â•â•â•â•â•â•â•â•â•â• Proof æ‹‰å–æµç¨‹ â•â•â•â•â•â•â•â•â•â•

    PG->>PM: pull_proofs(max_txns, max_bytes, excluded)

    rect rgb(225, 245, 255)
        Note over PM: Phase 1: æ¸…ç†è¿‡æœŸ
        PM->>PQ: clean_expired(now)
        PQ->>PQ: éå†æ‰€æœ‰ Proofs
        PQ->>PQ: ç§»é™¤ expiration < now
        PQ->>PM: cleaned
    end

    rect rgb(255, 249, 196)
        Note over PQ: Phase 2: ä»é˜Ÿåˆ—æ‹‰å–
        PM->>PQ: pull(max_bytes, excluded)

        loop éå† gas buckets (é«˜åˆ°ä½)
            PQ->>PQ: æ£€æŸ¥ excluded_batches
            alt æœªæ’é™¤ ä¸” æœªè¶…é™
                PQ->>PQ: æ·»åŠ åˆ° selected
            end
        end

        PQ->>PM: Vec<ProofOfStore>
    end

    rect rgb(243, 229, 245)
        Note over PM: Phase 3: è¿‡æ»¤äº¤æ˜“æ•°
        PM->>PM: total_txns = 0

        loop éå† proofs
            PM->>PM: total_txns += proof.num_txns()
            alt total_txns > max_txns
                PM->>PM: break
            else
                PM->>PM: æ·»åŠ åˆ° final_selected
            end
        end
    end

    PM->>PG: Vec<ProofOfStore>
```

### 6.3 æ¸…ç†æœºåˆ¶

#### handle_commit_notification å®ç°

```rust
impl ProofManager {
    /// å¤„ç†åŒºå—æäº¤é€šçŸ¥
    pub fn handle_commit_notification(
        &mut self,
        committed_round: Round,
        committed_batches: Vec<BatchId>,
    ) {
        info!(
            "Handling commit notification: round={}, {} batches",
            committed_round,
            committed_batches.len()
        );

        // ========================================
        // æ­¥éª¤ 1: è®°å½•å·²æäº¤çš„æ‰¹æ¬¡
        // ========================================
        self.committed_proofs
            .entry(committed_round)
            .or_insert_with(Vec::new);

        // ========================================
        // æ­¥éª¤ 2: æ¸…ç†æ—§çš„æäº¤è®°å½•ï¼ˆä¿ç•™æœ€è¿‘ 100 è½®ï¼‰
        // ========================================
        let cutoff_round = committed_round.saturating_sub(100);
        let old_rounds: Vec<_> = self.committed_proofs
            .range(..cutoff_round)
            .map(|(r, _)| *r)
            .collect();

        for round in old_rounds {
            self.committed_proofs.remove(&round);
        }

        counters::COMMITTED_PROOFS_CLEANED.inc_by(old_rounds.len() as u64);
    }
}
```

---

## 7. åå‹æœºåˆ¶è¯¦è§£

### 7.1 åå‹è§¦å‘æ¡ä»¶

#### BackPressure ç»“æ„

```mermaid
classDiagram
    class BackPressure {
        +bool txn_count
        +bool proof_count
        +update(metrics) void
        +should_backpressure() bool
    }

    class BackPressureMetrics {
        +usize pending_txns
        +usize pending_proofs
        +f64 mempool_utilization
        +Duration pipeline_latency
    }

    BackPressure --> BackPressureMetrics
```

**ä»£ç å®ç°**ï¼š

```rust
// src/quorum_store/batch_generator.rs

pub struct BackPressure {
    /// äº¤æ˜“æ•°åå‹æ ‡å¿—
    txn_count: bool,

    /// Proof æ•°åå‹æ ‡å¿—
    proof_count: bool,

    /// ä¸Šæ¬¡æ›´æ–°æ—¶é—´
    last_update: Instant,
}

impl BackPressure {
    pub fn new() -> Self {
        Self {
            txn_count: false,
            proof_count: false,
            last_update: Instant::now(),
        }
    }

    /// æ›´æ–°åå‹çŠ¶æ€
    pub fn update(&mut self, metrics: &BackPressureMetrics) {
        // ========================================
        // æ£€æŸ¥äº¤æ˜“æ•°åå‹
        // ========================================
        self.txn_count = metrics.pending_txns > metrics.txn_count_threshold;

        // ========================================
        // æ£€æŸ¥ Proof æ•°åå‹
        // ========================================
        self.proof_count = metrics.pending_proofs > metrics.proof_count_threshold;

        self.last_update = Instant::now();

        if self.txn_count || self.proof_count {
            warn!(
                "Backpressure active: txn_count={}, proof_count={}",
                self.txn_count,
                self.proof_count
            );

            counters::BACKPRESSURE_ACTIVE.set(1);
        } else {
            counters::BACKPRESSURE_ACTIVE.set(0);
        }
    }

    /// æ˜¯å¦åº”è¯¥åå‹
    pub fn should_backpressure(&self) -> bool {
        self.txn_count || self.proof_count
    }
}

pub struct BackPressureMetrics {
    /// å¾…å¤„ç†äº¤æ˜“æ•°
    pending_txns: usize,

    /// å¾…å¤„ç† Proof æ•°
    pending_proofs: usize,

    /// äº¤æ˜“æ•°é˜ˆå€¼
    txn_count_threshold: usize,

    /// Proof æ•°é˜ˆå€¼
    proof_count_threshold: usize,
}
```

### 7.2 åŠ¨æ€è°ƒæ§ç®—æ³•

#### åå‹å†³ç­–æµç¨‹

```mermaid
flowchart TD
    A[BatchGenerator.tick] --> B[æ”¶é›†æŒ‡æ ‡]

    B --> C[pending_txns = <br/>batches_in_progress.total_txns]
    B --> D[pending_proofs = <br/>proof_queue.size]

    C --> E{pending_txns > threshold?}
    D --> F{pending_proofs > threshold?}

    E -->|æ˜¯| G[txn_count_backpressure = true]
    E -->|å¦| H[txn_count_backpressure = false]

    F -->|æ˜¯| I[proof_count_backpressure = true]
    F -->|å¦| J[proof_count_backpressure = false]

    G --> K{ä»»ä¸€åå‹ = true?}
    H --> K
    I --> K
    J --> K

    K -->|æ˜¯| L[è·³è¿‡æ‰¹æ¬¡ç”Ÿæˆ]
    K -->|å¦| M[ç»§ç»­ç”Ÿæˆæ‰¹æ¬¡]

    L --> N[counters::BACKPRESSURE_SKIP.inc]
    M --> O[generate_batch]

    style G fill:#ffcdd2
    style I fill:#ffcdd2
    style L fill:#ffebee
    style M fill:#c8e6c9
```

### 7.3 å¤šçº§åå‹ç­–ç•¥

#### åå‹çº§åˆ«è¡¨

| çº§åˆ« | pending_txns | pending_proofs | åŠ¨ä½œ | æ•ˆæœ |
|-----|--------------|----------------|------|------|
| **Level 0 (æ­£å¸¸)** | < 10,000 | < 100 | æ­£å¸¸ç”Ÿæˆ | æœ€å¤§ååé‡ |
| **Level 1 (è½»å¾®)** | 10,000 - 20,000 | 100 - 200 | å‡å°‘ 20% | ç¼“è§£å‹åŠ› |
| **Level 2 (ä¸­ç­‰)** | 20,000 - 30,000 | 200 - 300 | å‡å°‘ 50% | æ˜¾è‘—é™ä½ |
| **Level 3 (ä¸¥é‡)** | > 30,000 | > 300 | å®Œå…¨åœæ­¢ | ç³»ç»Ÿä¿æŠ¤ |

**å¤šçº§åå‹å®ç°**ï¼š

```rust
impl BackPressure {
    /// è®¡ç®—åå‹çº§åˆ«
    pub fn calculate_level(&self, metrics: &BackPressureMetrics) -> BackPressureLevel {
        let txn_ratio = metrics.pending_txns as f64 / metrics.txn_count_threshold as f64;
        let proof_ratio = metrics.pending_proofs as f64 / metrics.proof_count_threshold as f64;

        let max_ratio = txn_ratio.max(proof_ratio);

        if max_ratio < 1.0 {
            BackPressureLevel::Normal
        } else if max_ratio < 2.0 {
            BackPressureLevel::Mild
        } else if max_ratio < 3.0 {
            BackPressureLevel::Moderate
        } else {
            BackPressureLevel::Severe
        }
    }

    /// æ ¹æ®çº§åˆ«è°ƒæ•´ç”Ÿæˆé€Ÿç‡
    pub fn adjust_rate(&self, level: BackPressureLevel, base_rate: f64) -> f64 {
        match level {
            BackPressureLevel::Normal => base_rate,
            BackPressureLevel::Mild => base_rate * 0.8,
            BackPressureLevel::Moderate => base_rate * 0.5,
            BackPressureLevel::Severe => 0.0,
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum BackPressureLevel {
    Normal,
    Mild,
    Moderate,
    Severe,
}
```

---

## 8. ç½‘ç»œå±‚äº¤äº’

### 8.1 æ¶ˆæ¯ç±»å‹

#### QuorumStoreMsg æšä¸¾

```rust
// src/quorum_store/types.rs

#[derive(Clone, Debug, Serialize, Deserialize)]
pub enum QuorumStoreMsg {
    /// æ‰¹æ¬¡æ¶ˆæ¯ï¼ˆåŒ…å«å®Œæ•´äº¤æ˜“ï¼‰
    BatchMsg(BatchMsg),

    /// ç­¾åçš„æ‰¹æ¬¡ä¿¡æ¯
    SignedBatchInfoMsg(SignedBatchInfoMsg),

    /// Proof æ¶ˆæ¯ï¼ˆå¯é€‰ï¼Œç”¨äºä¸»åŠ¨æ¨é€ï¼‰
    ProofOfStoreMsg(ProofOfStoreMsg),

    /// æ‰¹æ¬¡è¯·æ±‚
    BatchRequest(BatchRequest),

    /// æ‰¹æ¬¡å“åº”
    BatchResponse(BatchResponse),
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct BatchMsg {
    batch: Batch,
    signature: bls12381::Signature,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct SignedBatchInfoMsg {
    signed_batch_info: SignedBatchInfo,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct BatchRequest {
    epoch: u64,
    batch_ids: Vec<BatchId>,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct BatchResponse {
    batches: Vec<Batch>,
}
```

#### æ¶ˆæ¯æµå›¾

```mermaid
graph TB
    subgraph "Validator A (Generator)"
        A1[ç”Ÿæˆ Batch]
        A2[å¹¿æ’­ BatchMsg]
    end

    subgraph "Validator B (Receiver)"
        B1[æ¥æ”¶ BatchMsg]
        B2[æŒä¹…åŒ– Batch]
        B3[ç­¾å BatchInfo]
        B4[å‘é€ SignedBatchInfoMsg]
    end

    subgraph "Validator C (Receiver)"
        C1[æ¥æ”¶ BatchMsg]
        C2[æŒä¹…åŒ– Batch]
        C3[ç­¾å BatchInfo]
        C4[å‘é€ SignedBatchInfoMsg]
    end

    subgraph "Validator A (Aggregator)"
        A3[æ”¶é›† SignedBatchInfoMsg]
        A4[èšåˆç­¾å]
        A5[ç”Ÿæˆ ProofOfStore]
    end

    A1 --> A2
    A2 -->|broadcast| B1
    A2 -->|broadcast| C1

    B1 --> B2 --> B3 --> B4
    C1 --> C2 --> C3 --> C4

    B4 -->|send back| A3
    C4 -->|send back| A3

    A3 --> A4 --> A5

    style A1 fill:#c8e6c9
    style A5 fill:#e1f5ff
```

### 8.2 å¹¿æ’­æœºåˆ¶

#### broadcast_batch_msg å®ç°

```rust
impl QuorumStoreNetworkSender {
    /// å¹¿æ’­æ‰¹æ¬¡æ¶ˆæ¯
    pub async fn broadcast_batch_msg(&self, batch: Batch) {
        let batch_msg = BatchMsg {
            batch: batch.clone(),
            signature: self.signer.sign(&batch.digest()).unwrap(),
        };

        let msg = QuorumStoreMsg::BatchMsg(batch_msg);

        // ========================================
        // å‘é€ç»™æ‰€æœ‰å…¶ä»–éªŒè¯è€…
        // ========================================
        let recipients: Vec<_> = self.epoch_state
            .verifier()
            .get_ordered_account_addresses()
            .into_iter()
            .filter(|addr| *addr != self.author)
            .collect();

        info!(
            "Broadcasting batch {} to {} validators",
            batch.batch_id(),
            recipients.len()
        );

        for recipient in recipients {
            if let Err(e) = self.network
                .send_to(recipient, msg.clone())
                .await
            {
                warn!("Failed to send batch to {}: {:?}", recipient, e);
                counters::BATCH_BROADCAST_FAILED.inc();
            }
        }

        counters::BATCH_BROADCAST_SENT.inc();
    }

    /// å‘é€ç­¾åçš„æ‰¹æ¬¡ä¿¡æ¯
    pub async fn send_signed_batch_info(
        &self,
        recipient: Author,
        signed_batch_info: SignedBatchInfo,
    ) {
        let msg = QuorumStoreMsg::SignedBatchInfoMsg(
            SignedBatchInfoMsg {
                signed_batch_info,
            }
        );

        if let Err(e) = self.network.send_to(recipient, msg).await {
            warn!(
                "Failed to send SignedBatchInfo to {}: {:?}",
                recipient,
                e
            );
        }
    }
}
```

### 8.3 è¯·æ±‚ä¸å“åº”

#### BatchRequester RPC å®ç°

```rust
// src/quorum_store/batch_requester.rs

pub struct BatchRequester {
    network: Arc<NetworkClient>,
    batch_store: Arc<BatchStore>,
    timeout: Duration,
}

impl BatchRequester {
    /// è¯·æ±‚ç¼ºå¤±çš„æ‰¹æ¬¡
    pub async fn request_batches(
        &self,
        missing_batch_ids: Vec<BatchId>,
        preferred_peer: Author,
    ) -> anyhow::Result<Vec<Batch>> {
        if missing_batch_ids.is_empty() {
            return Ok(Vec::new());
        }

        info!(
            "Requesting {} batches from {}",
            missing_batch_ids.len(),
            preferred_peer
        );

        // ========================================
        // æ„é€ è¯·æ±‚
        // ========================================
        let request = BatchRequest {
            epoch: self.epoch,
            batch_ids: missing_batch_ids.clone(),
        };

        // ========================================
        // å‘é€ RPC è¯·æ±‚
        // ========================================
        let response = tokio::time::timeout(
            self.timeout,
            self.network.request_batches(preferred_peer, request),
        )
        .await??;

        // ========================================
        // éªŒè¯å“åº”
        // ========================================
        let mut fetched_batches = Vec::new();

        for batch in response.batches {
            // éªŒè¯æ‰¹æ¬¡å®Œæ•´æ€§
            if missing_batch_ids.contains(&batch.batch_id()) {
                // æŒä¹…åŒ–åˆ°æœ¬åœ°
                self.batch_store.persist_batch(batch.clone()).await?;

                fetched_batches.push(batch);
            }
        }

        info!("Fetched {} batches", fetched_batches.len());

        counters::BATCHES_FETCHED.inc_by(fetched_batches.len() as u64);

        Ok(fetched_batches)
    }
}

/// å¤„ç†æ‰¹æ¬¡è¯·æ±‚ï¼ˆæœåŠ¡ç«¯ï¼‰
pub async fn handle_batch_request(
    request: BatchRequest,
    batch_store: Arc<BatchStore>,
) -> anyhow::Result<BatchResponse> {
    let mut batches = Vec::new();

    for batch_id in request.batch_ids {
        let key = BatchKey::new(batch_id.author, batch_id);

        if let Some(batch) = batch_store.get_batch(&key).await? {
            batches.push(batch);
        }
    }

    Ok(BatchResponse { batches })
}
```

---

## 9. Batch å®Œæ•´ç”Ÿå‘½å‘¨æœŸ

### ç«¯åˆ°ç«¯æµç¨‹

```mermaid
sequenceDiagram
    autonumber
    participant MP as Mempool
    participant BG as BatchGenerator
    participant BS as BatchStore
    participant NET as Network
    participant PEERS as Other Validators
    participant PC as ProofCoordinator
    participant PM as ProofManager
    participant PG as ProposalGenerator
    participant EX as Executor
    participant COMMIT as Commit

    Note over MP,COMMIT: â•â•â•â•â•â•â•â•â•â• å®Œæ•´ç”Ÿå‘½å‘¨æœŸ â•â•â•â•â•â•â•â•â•â•

    rect rgb(225, 245, 255)
        Note over BG: Phase 1: æ‰¹æ¬¡ç”Ÿæˆ
        BG->>BG: timer tick (100ms)
        BG->>MP: pull_txns(max, excluded)
        MP->>BG: Vec<SignedTransaction>
        BG->>BG: create Batch
    end

    rect rgb(255, 249, 196)
        Note over BS: Phase 2: æŒä¹…åŒ–
        BG->>BS: persist_batch(batch)
        BS->>BS: quota_check()
        BS->>BS: write to RocksDB + cache
        BS->>BS: sign BatchInfo
        BS->>BG: SignedBatchInfo
    end

    rect rgb(243, 229, 245)
        Note over NET: Phase 3: å¹¿æ’­
        BG->>NET: broadcast BatchMsg
        NET->>PEERS: send to all
        PEERS->>PEERS: persist & sign
        PEERS->>NET: SignedBatchInfoMsg
    end

    rect rgb(255, 235, 238)
        Note over PC: Phase 4: ç­¾åèšåˆ
        NET->>PC: collect signatures
        PC->>PC: voting_power >= 2f+1?
        PC->>PC: aggregate signatures
        PC->>PM: ProofOfStore ready
    end

    rect rgb(200, 230, 201)
        Note over PG: Phase 5: åŒºå—ææ¡ˆ
        PG->>PM: pull_proofs(max_bytes)
        PM->>PG: Vec<ProofOfStore>
        PG->>PG: construct block
        PG->>NET: broadcast proposal
    end

    rect rgb(225, 245, 255)
        Note over EX: Phase 6: æ‰§è¡Œ
        EX->>EX: receive block
        EX->>BS: fetch batches (by ProofOfStore)
        BS->>EX: Vec<Batch>
        EX->>EX: execute transactions
    end

    rect rgb(255, 249, 196)
        Note over COMMIT: Phase 7: æäº¤ä¸æ¸…ç†
        COMMIT->>BG: commit_notify(committed_batches)
        BG->>BG: cleanup expired batches
        BG->>BS: release quota
        BS->>BS: free memory & disk
    end
```

### æ—¶é—´çº¿å¯è§†åŒ–

```mermaid
gantt
    title Batch ç”Ÿå‘½å‘¨æœŸæ—¶é—´çº¿ (å•ä½: ms)
    dateFormat X
    axisFormat %L

    section Generation
    æ‹‰å–äº¤æ˜“ (0-100ms)           :active, g1, 0, 100
    åˆ›å»ºæ‰¹æ¬¡ (100-110ms)         :active, g2, 100, 10
    æŒä¹…åŒ– (110-150ms)           :active, g3, 110, 40

    section Broadcast
    å¹¿æ’­ BatchMsg (150-200ms)    :crit, b1, 150, 50
    ç½‘ç»œä¼ è¾“ (200-300ms)         :crit, b2, 200, 100

    section Signature
    è¿œç¨‹æŒä¹…åŒ– (300-400ms)       :active, s1, 300, 100
    ç­¾åæ”¶é›† (400-600ms)         :active, s2, 400, 200
    èšåˆç­¾å (600-610ms)         :active, s3, 600, 10
    ProofOfStore ç”Ÿæˆ (610-620ms):done, s4, 610, 10

    section Proposal
    ç­‰å¾…åŒºå—ææ¡ˆ (620-1000ms)    :milestone, p1, 620, 380
    åŒ…å«åœ¨åŒºå— (1000ms)          :crit, p2, 1000, 0

    section Execution
    åŒºå—æ‰§è¡Œ (1000-1500ms)       :active, e1, 1000, 500
    åŒºå—æäº¤ (1500-1600ms)       :done, e2, 1500, 100

    section Cleanup
    æ¸…ç†é€šçŸ¥ (1600-1650ms)       :crit, c1, 1600, 50
    é‡Šæ”¾èµ„æº (1650-1700ms)       :done, c2, 1650, 50
```

---

## 10. æ€§èƒ½ä¼˜åŒ–ä¸é…ç½®

### æ€§èƒ½æŒ‡æ ‡æ€»ç»“

```mermaid
graph TB
    subgraph "QuorumStore æ€§èƒ½æå‡"
        A[ç½‘ç»œå¸¦å®½<br/>å‡å°‘ 50-70%]
        B[ååé‡<br/>æå‡ 3-5å€]
        C[å…±è¯†å»¶è¿Ÿ<br/>å‡å°‘ 30%]
        D[å­˜å‚¨å¤ç”¨<br/>é«˜å¤ç”¨ç‡]
    end

    subgraph "ä¼˜åŒ–æŠ€æœ¯"
        E[æ‰¹é‡å¤„ç†<br/>500 txns/batch]
        F[è§£è€¦ä¼ æ’­<br/>å¼‚æ­¥å¹¶è¡Œ]
        G[åŠ¨æ€åå‹<br/>å¹³æ»‘è´Ÿè½½]
        H[ä¸‰çº§å­˜å‚¨<br/>å†…å­˜+ç£ç›˜]
    end

    A --> E
    B --> F
    C --> F
    D --> H

    style A fill:#c8e6c9
    style B fill:#c8e6c9
    style C fill:#c8e6c9
    style D fill:#c8e6c9
```

### å…³é”®é…ç½®å‚æ•°

```toml
# config.toml

[consensus.quorum_store]
# ========================================
# Batch é…ç½®
# ========================================
# å•ä¸ª Batch æœ€å¤§äº¤æ˜“æ•°
max_batch_txns = 500

# å•ä¸ª Batch æœ€å¤§å­—èŠ‚æ•°
max_batch_bytes = 524288  # 512KB

# Batch è¿‡æœŸæ—¶é—´ï¼ˆå¾®ç§’ï¼‰
batch_expiry_time_usecs = 60000000  # 60 ç§’

# Batch ç”Ÿæˆé—´éš”ï¼ˆæ¯«ç§’ï¼‰
batch_generation_interval_ms = 100

# ========================================
# é…é¢ç®¡ç†
# ========================================
# å†…å­˜é…é¢ï¼ˆå­—èŠ‚ï¼‰
memory_quota = 125829120  # 120MB

# ç£ç›˜é…é¢ï¼ˆå­—èŠ‚ï¼‰
db_quota = 1006632960  # 960MB

# æ‰¹æ¬¡æ•°é…é¢
batch_quota = 2500

# ========================================
# åå‹é…ç½®
# ========================================
# äº¤æ˜“æ•°åå‹é˜ˆå€¼
txn_count_threshold = 10000

# Proof æ•°åå‹é˜ˆå€¼
proof_count_threshold = 100

# åå‹æ£€æŸ¥é—´éš”ï¼ˆæ¯«ç§’ï¼‰
backpressure_check_interval_ms = 200

# ========================================
# ç½‘ç»œé…ç½®
# ========================================
# Batch è¯·æ±‚è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
batch_request_timeout_ms = 5000

# æœ€å¤§é‡è¯•æ¬¡æ•°
max_batch_request_retries = 3

# ========================================
# ProofQueue é…ç½®
# ========================================
# Proof é˜Ÿåˆ—æœ€å¤§å­—èŠ‚æ•°
proof_queue_max_bytes = 10485760  # 10MB

# Proof é˜Ÿåˆ—æ¸…ç†é—´éš”ï¼ˆæ¯«ç§’ï¼‰
proof_queue_cleanup_interval_ms = 1000
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

| åœºæ™¯ | å‚æ•°è°ƒæ•´ | æ•ˆæœ |
|-----|---------|------|
| **é«˜ååé‡** | å¢å¤§ `max_batch_txns` åˆ° 1000 | å•æ‰¹æ¬¡åŒ…å«æ›´å¤šäº¤æ˜“ |
| | å¢å¤§ `memory_quota` åˆ° 200MB | å‡å°‘ç£ç›˜ I/O |
| | å‡å°‘ `batch_generation_interval_ms` åˆ° 50ms | æ›´é¢‘ç¹ç”Ÿæˆæ‰¹æ¬¡ |
| **ä½å»¶è¿Ÿ** | å‡å°‘ `max_batch_txns` åˆ° 200 | æ‰¹æ¬¡æ›´å°æ›´å¿« |
| | å¢åŠ  `batch_generation_interval_ms` åˆ° 200ms | ç­‰å¾…æ›´å¤šäº¤æ˜“èšåˆ |
| **èµ„æºå—é™** | å‡å°‘ `memory_quota` åˆ° 50MB | èŠ‚çœå†…å­˜ |
| | å‡å°‘ `batch_quota` åˆ° 1000 | é™åˆ¶æ‰¹æ¬¡æ•° |
| **ç½‘ç»œæ‹¥å¡** | å¯ç”¨æ›´æ¿€è¿›çš„åå‹ | é™ä½ç½‘ç»œå‹åŠ› |
| | å‡å°‘ `max_batch_bytes` åˆ° 256KB | æ‰¹æ¬¡æ›´å° |

### Prometheus ç›‘æ§æŒ‡æ ‡

```rust
// src/quorum_store/counters.rs

/// æ‰¹æ¬¡ç”ŸæˆæŒ‡æ ‡
pub static BATCH_GENERATED: Lazy<IntCounter> = ...;
pub static BATCH_GENERATED_TXNS: Lazy<IntCounter> = ...;
pub static BATCH_GENERATED_BYTES: Lazy<IntCounter> = ...;

/// æ‰¹æ¬¡æŒä¹…åŒ–æŒ‡æ ‡
pub static BATCH_PERSISTED: Lazy<IntCounter> = ...;
pub static BATCH_CACHE_HIT: Lazy<IntCounter> = ...;
pub static BATCH_CACHE_MISS: Lazy<IntCounter> = ...;

/// é…é¢æŒ‡æ ‡
pub static QUOTA_MEMORY_USAGE: Lazy<IntGauge> = ...;
pub static QUOTA_DB_USAGE: Lazy<IntGauge> = ...;
pub static EXCEEDED_BATCH_QUOTA_COUNT: Lazy<IntCounter> = ...;

/// Proof æŒ‡æ ‡
pub static PROOFS_GENERATED: Lazy<IntCounter> = ...;
pub static PROOFS_PULLED: Lazy<IntCounter> = ...;
pub static PROOF_QUEUE_SIZE_BYTES: Lazy<IntGauge> = ...;

/// åå‹æŒ‡æ ‡
pub static BACKPRESSURE_ACTIVE: Lazy<IntGauge> = ...;
pub static BATCH_GENERATOR_BACKPRESSURE: Lazy<IntCounter> = ...;

/// ç½‘ç»œæŒ‡æ ‡
pub static BATCH_BROADCAST_SENT: Lazy<IntCounter> = ...;
pub static BATCH_BROADCAST_FAILED: Lazy<IntCounter> = ...;
pub static BATCHES_FETCHED: Lazy<IntCounter> = ...;
```

---

## 11. æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

```mermaid
mindmap
  root((QuorumStore æ€»ç»“))
    è®¾è®¡ç†å¿µ
      è§£è€¦æ•°æ®ä¼ æ’­ä¸å…±è¯†
      æ‰¹é‡å¤„ç†æå‡æ•ˆç‡
      å¼‚æ­¥å¹¶è¡Œä¼˜åŒ–æ€§èƒ½
    æ ¸å¿ƒç»„ä»¶
      BatchGenerator
        å®šæ—¶ç”Ÿæˆæ‰¹æ¬¡
        äº¤æ˜“å»é‡æœºåˆ¶
        è¿‡æœŸç®¡ç†
      BatchStore
        ä¸‰çº§å­˜å‚¨æ¶æ„
        é…é¢ç®¡ç†
        ç­¾åéªŒè¯
      ProofCoordinator
        ç­¾åæ”¶é›†
        èšåˆç­¾å
        ProofOfStore ç”Ÿæˆ
      ProofManager
        ä¼˜å…ˆé˜Ÿåˆ—
        æ‹‰å–ç­–ç•¥
        æ¸…ç†æœºåˆ¶
    åå‹æœºåˆ¶
      å¤šçº§åå‹ç­–ç•¥
      åŠ¨æ€è°ƒæ§ç®—æ³•
      ç³»ç»Ÿä¿æŠ¤
    æ€§èƒ½ä¼˜åŠ¿
      ç½‘ç»œå¸¦å®½å‡å°‘ 50-70%
      ååé‡æå‡ 3-5å€
      å…±è¯†å»¶è¿Ÿå‡å°‘ 30%
      å­˜å‚¨é«˜å¤ç”¨ç‡
```

### å…³é”®ç®—æ³•æ€»ç»“

| ç®—æ³• | æ—¶é—´å¤æ‚åº¦ | ç©ºé—´å¤æ‚åº¦ | è¯´æ˜ |
|-----|-----------|-----------|------|
| **äº¤æ˜“å»é‡** | O(n) | O(m) | n=æ–°äº¤æ˜“æ•°, m=è¿›è¡Œä¸­äº¤æ˜“æ•° |
| **Batch æŒä¹…åŒ–** | O(1) | O(b) | b=æ‰¹æ¬¡å¤§å° |
| **ç­¾åèšåˆ** | O(k) | O(k) | k=ç­¾åæ•°é‡ |
| **Proof æ‹‰å–** | O(log m + n) | O(n) | m=gas buckets, n=æ‹‰å–æ•° |
| **é…é¢æ£€æŸ¥** | O(1) | O(1) | å¸¸é‡æ—¶é—´ |

### è®¾è®¡äº®ç‚¹

1. **è§£è€¦æ¶æ„**: æ•°æ®ä¼ æ’­ä¸å…±è¯†å®Œå…¨åˆ†ç¦»ï¼Œäº’ä¸é˜»å¡
2. **æ‰¹é‡ä¼˜åŒ–**: 500 txns/batchï¼Œæ˜¾è‘—å‡å°‘ç½‘ç»œå¼€é”€
3. **ä¸‰çº§å­˜å‚¨**: å†…å­˜ + ç£ç›˜ + é…é¢ç®¡ç†ï¼Œçµæ´»é«˜æ•ˆ
4. **åŠ¨æ€åå‹**: å¤šçº§ç­–ç•¥è‡ªé€‚åº”è°ƒèŠ‚ï¼Œç³»ç»Ÿç¨³å®š
5. **ä¼˜å…ˆé˜Ÿåˆ—**: æŒ‰ gas æ’åºï¼Œä¿è¯é«˜ä»·å€¼äº¤æ˜“ä¼˜å…ˆ
6. **å¹¶è¡Œå¤„ç†**: äº¤æ˜“æ‘˜è¦å¹¶è¡Œè®¡ç®—ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸

### QuorumStore vs ä¼ ç»Ÿæ¨¡å¼å¯¹æ¯”

| ç»´åº¦ | ä¼ ç»Ÿæ¨¡å¼ | QuorumStore æ¨¡å¼ | æ”¹è¿›å¹…åº¦ |
|-----|---------|-----------------|---------|
| **ç½‘ç»œå¸¦å®½** | æ¯è½®å®Œæ•´äº¤æ˜“ | äº¤æ˜“ä¼ è¾“ä¸€æ¬¡ + Proof | **50-70% â†“** |
| **ååé‡** | ~20k TPS | ~60-100k TPS | **3-5å€** |
| **å…±è¯†å»¶è¿Ÿ** | 1-2ç§’ | 700ms-1.4ç§’ | **30% â†“** |
| **å­˜å‚¨å¤ç”¨** | æ—  | Batch å¯è¢«å¤šä¸ªåŒºå—å¼•ç”¨ | **é«˜å¤ç”¨ç‡** |
| **å³°å€¼å¤„ç†** | æ— ç¼“å†² | åŠ¨æ€åå‹å¹³æ»‘è´Ÿè½½ | **æ˜¾è‘—æ”¹å–„** |
| **æ‰©å±•æ€§** | Leader ç“¶é¢ˆ | å¤šèŠ‚ç‚¹å¹¶è¡Œæ‰¹å¤„ç† | **æ›´å¥½** |

### é€‚ç”¨åœºæ™¯

- âœ… **é«˜ååé‡åŒºå—é“¾**: éœ€è¦å¤„ç†å¤§é‡äº¤æ˜“çš„å…¬é“¾
- âœ… **ç½‘ç»œå¸¦å®½å—é™**: å‡å°‘æ•°æ®ä¼ è¾“é‡è‡³å…³é‡è¦
- âœ… **å³°å€¼æµé‡åœºæ™¯**: éœ€è¦å¹³æ»‘è´Ÿè½½çš„ç³»ç»Ÿ
- âœ… **å¤šéªŒè¯è€…ç½‘ç»œ**: å……åˆ†åˆ©ç”¨åˆ†å¸ƒå¼æ‰¹å¤„ç†èƒ½åŠ›

---

**æ–‡æ¡£è·¯å¾„**: `/home/morton/work/rust/aptos-core/consensus/APTOS_å…±è¯†æ¨¡å—æ·±åº¦æŠ€æœ¯æ–‡æ¡£_è¯¦ç»†å¢å¼ºç‰ˆ_Part7_QuorumStore.md`

**ç”Ÿæˆæ—¶é—´**: 2025-10-09
**æ–‡æ¡£ç‰ˆæœ¬**: v2.0 (è¯¦ç»†å¢å¼ºç‰ˆ)
**æºç è·¯å¾„**: `consensus/src/quorum_store/`

---

## ğŸ‰ Aptos Consensus æ¨¡å—å®Œæ•´ç³»åˆ—æ–‡æ¡£

æœ¬æ–‡æ¡£æ˜¯ **Aptos å…±è¯†æ¨¡å—æ·±åº¦æŠ€æœ¯æ–‡æ¡£** ç³»åˆ—çš„æœ€åä¸€éƒ¨åˆ†ã€‚å®Œæ•´ç³»åˆ—åŒ…æ‹¬ï¼š

1. **Part 1**: æ¨¡å—æ¦‚è¿°ä¸æ•´ä½“æ¶æ„
2. **Part 2**: SafetyRules å®‰å…¨è§„åˆ™è¯¦è§£
3. **Part 3**: BlockStorage ä¸ RoundManager è¯¦è§£
4. **Part 4**: Liveness æ¨¡å—è¯¦è§£
5. **Part 5**: Pipeline æ¨¡å—è¯¦è§£
6. **Part 6**: DAG å…±è¯†æ¨¡å—è¯¦è§£
7. **Part 7**: QuorumStore æ¨¡å—è¯¦è§£ âœ… (å½“å‰æ–‡æ¡£)

æ„Ÿè°¢é˜…è¯»ï¼ğŸ™
